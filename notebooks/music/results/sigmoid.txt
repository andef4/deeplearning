9 layers, dropout, 500 neurons, sigmoid, 0.0001 learning rate
Epoch: 0, Train Loss: -0.3320761501789093, Validation Loss: -0.3352774977684021
Epoch: 1, Train Loss: -0.33469614519013297, Validation Loss: -0.3352881073951721
Epoch: 2, Train Loss: -0.3304445935620202, Validation Loss: -0.3353022634983063
Epoch: 3, Train Loss: -0.3325149264600542, Validation Loss: -0.33503445982933044
Epoch: 4, Train Loss: -0.33018808960914614, Validation Loss: -0.3345128297805786
Epoch: 5, Train Loss: -0.33619463907347785, Validation Loss: -0.3341556191444397
Epoch: 6, Train Loss: -0.33422308829095626, Validation Loss: -0.33388492465019226
Epoch: 7, Train Loss: -0.32724794546763103, Validation Loss: -0.3336183726787567
Epoch: 8, Train Loss: -0.32796270781093173, Validation Loss: -0.3331781327724457
Epoch: 9, Train Loss: -0.3367572943369547, Validation Loss: -0.3328371047973633
Epoch: 10, Train Loss: -0.33228284385469226, Validation Loss: -0.3330312669277191
Epoch: 11, Train Loss: -0.3329080171055264, Validation Loss: -0.3328219950199127
Epoch: 12, Train Loss: -0.3306071443690194, Validation Loss: -0.33261939883232117
Epoch: 13, Train Loss: -0.33256754444705117, Validation Loss: -0.332411527633667
Epoch: 14, Train Loss: -0.3304193006621467, Validation Loss: -0.3321514427661896
Epoch: 15, Train Loss: -0.3364144417974684, Validation Loss: -0.3322048783302307
Epoch: 16, Train Loss: -0.33667429685592654, Validation Loss: -0.3319845199584961
Epoch: 17, Train Loss: -0.3360096428129408, Validation Loss: -0.3318270742893219
Epoch: 18, Train Loss: -0.3299296498298645, Validation Loss: -0.33169111609458923
Epoch: 19, Train Loss: -0.33654152817196314, Validation Loss: -0.3317301869392395
Epoch: 20, Train Loss: -0.33501198689142864, Validation Loss: -0.3315618336200714
Epoch: 21, Train Loss: -0.33398461871676977, Validation Loss: -0.3314703106880188
Epoch: 22, Train Loss: -0.3272563378016154, Validation Loss: -0.3310262858867645
Epoch: 23, Train Loss: -0.3335091961754693, Validation Loss: -0.3307648301124573
Epoch: 24, Train Loss: -0.3319582058323754, Validation Loss: -0.3306412994861603
Epoch: 25, Train Loss: -0.33467645512686833, Validation Loss: -0.3308463394641876
Epoch: 26, Train Loss: -0.33605535493956673, Validation Loss: -0.3308689594268799
Epoch: 27, Train Loss: -0.3329462104373508, Validation Loss: -0.33081701397895813
Epoch: 28, Train Loss: -0.33405926095114813, Validation Loss: -0.33057937026023865
Epoch: 29, Train Loss: -0.3345514065689511, Validation Loss: -0.3304542899131775
Epoch: 30, Train Loss: -0.328415819340282, Validation Loss: -0.3302147090435028
Epoch: 31, Train Loss: -0.337316405110889, Validation Loss: -0.3301351070404053
Epoch: 32, Train Loss: -0.33369797666867573, Validation Loss: -0.330080509185791
Epoch: 33, Train Loss: -0.33104387919108075, Validation Loss: -0.3300825357437134
Epoch: 34, Train Loss: -0.33363990585009257, Validation Loss: -0.32999980449676514
Epoch: 35, Train Loss: -0.3288023233413696, Validation Loss: -0.3299205005168915
Epoch: 36, Train Loss: -0.33583547936545477, Validation Loss: -0.3297611176967621
Epoch: 37, Train Loss: -0.3320667882760366, Validation Loss: -0.3297854959964752
Epoch: 38, Train Loss: -0.33083320657412213, Validation Loss: -0.32990577816963196
Epoch: 39, Train Loss: -0.3350780990388658, Validation Loss: -0.32986679673194885
Epoch: 40, Train Loss: -0.3322317719459534, Validation Loss: -0.3297808766365051
Epoch: 41, Train Loss: -0.3291008916166094, Validation Loss: -0.32974904775619507
Epoch: 42, Train Loss: -0.3314664085706075, Validation Loss: -0.32967209815979004
Epoch: 43, Train Loss: -0.3324744847085741, Validation Loss: -0.32982465624809265
Epoch: 44, Train Loss: -0.3360033813450072, Validation Loss: -0.32981234788894653
Epoch: 45, Train Loss: -0.32587033443980745, Validation Loss: -0.3297857344150543
Epoch: 46, Train Loss: -0.336605257458157, Validation Loss: -0.32983267307281494
Epoch: 47, Train Loss: -0.32957775162325964, Validation Loss: -0.329684317111969
Epoch: 48, Train Loss: -0.33403158055411447, Validation Loss: -0.329675555229187
Epoch: 49, Train Loss: -0.3348452425665326, Validation Loss: -0.32958972454071045
Epoch: 50, Train Loss: -0.3367976658874088, Validation Loss: -0.3295682668685913
Epoch: 51, Train Loss: -0.33334910141097174, Validation Loss: -0.32969167828559875
Epoch: 52, Train Loss: -0.33598217401239605, Validation Loss: -0.3296626806259155
Epoch: 53, Train Loss: -0.334584488802486, Validation Loss: -0.3295844793319702
Epoch: 54, Train Loss: -0.3293980422947142, Validation Loss: -0.3293594419956207
Epoch: 55, Train Loss: -0.33766802748044333, Validation Loss: -0.3293301463127136
Epoch: 56, Train Loss: -0.3381874703698688, Validation Loss: -0.32932525873184204
Epoch: 57, Train Loss: -0.33567254609531827, Validation Loss: -0.3292011320590973
Epoch: 58, Train Loss: -0.3291894131236606, Validation Loss: -0.32906395196914673
Epoch: 59, Train Loss: -0.332423292265998, Validation Loss: -0.32900798320770264
Epoch: 60, Train Loss: -0.33759115404552886, Validation Loss: -0.3289259672164917
Epoch: 61, Train Loss: -0.3401682131820255, Validation Loss: -0.3287564516067505
Epoch: 62, Train Loss: -0.3339518643087811, Validation Loss: -0.3287053108215332
Epoch: 63, Train Loss: -0.33219732178582084, Validation Loss: -0.32867223024368286
Epoch: 64, Train Loss: -0.3353868087132772, Validation Loss: -0.32872575521469116
Epoch: 65, Train Loss: -0.3371369159883923, Validation Loss: -0.3286539316177368
Epoch: 66, Train Loss: -0.33617227640416886, Validation Loss: -0.3286283016204834
Epoch: 67, Train Loss: -0.3332847250832452, Validation Loss: -0.3286082446575165
Epoch: 68, Train Loss: -0.3344592193762461, Validation Loss: -0.328518807888031
Epoch: 69, Train Loss: -0.330984357992808, Validation Loss: -0.32847657799720764
Epoch: 70, Train Loss: -0.3338951544629203, Validation Loss: -0.32843008637428284
Epoch: 71, Train Loss: -0.3327801999118593, Validation Loss: -0.3283407688140869
Epoch: 72, Train Loss: -0.33390609754456413, Validation Loss: -0.32820817828178406
Epoch: 73, Train Loss: -0.33447352747122444, Validation Loss: -0.3281589150428772
Epoch: 74, Train Loss: -0.3371280074119568, Validation Loss: -0.32823073863983154
Epoch: 75, Train Loss: -0.3351589500904083, Validation Loss: -0.328317791223526
Epoch: 76, Train Loss: -0.3380556712547938, Validation Loss: -0.3283064365386963
Epoch: 77, Train Loss: -0.3362338976727592, Validation Loss: -0.3282369077205658
Epoch: 78, Train Loss: -0.3311368425687154, Validation Loss: -0.32818403840065
Epoch: 79, Train Loss: -0.33091145058472954, Validation Loss: -0.3281495273113251
Epoch: 80, Train Loss: -0.3387913190656238, Validation Loss: -0.32814183831214905
Epoch: 81, Train Loss: -0.33535855809847515, Validation Loss: -0.32811111211776733
Epoch: 82, Train Loss: -0.33771225478914046, Validation Loss: -0.32817208766937256
Epoch: 83, Train Loss: -0.33303458193937935, Validation Loss: -0.32814252376556396
Epoch: 84, Train Loss: -0.33779936134815214, Validation Loss: -0.32812801003456116
Epoch: 85, Train Loss: -0.33659911652406055, Validation Loss: -0.328167587518692
Epoch: 86, Train Loss: -0.33167948292361366, Validation Loss: -0.3280714154243469
Epoch: 87, Train Loss: -0.33224274449878266, Validation Loss: -0.32799065113067627
Epoch: 88, Train Loss: -0.3287450290388531, Validation Loss: -0.3278568983078003
Epoch: 89, Train Loss: -0.33306531608104706, Validation Loss: -0.32772648334503174
Epoch: 90, Train Loss: -0.33234988782140945, Validation Loss: -0.3275948166847229
Epoch: 91, Train Loss: -0.3312656018469069, Validation Loss: -0.32748082280158997
Epoch: 92, Train Loss: -0.33515097035302055, Validation Loss: -0.3274703025817871
Epoch: 93, Train Loss: -0.3326859359939893, Validation Loss: -0.3274046778678894
Epoch: 94, Train Loss: -0.3343797187010447, Validation Loss: -0.3273276388645172
Epoch: 95, Train Loss: -0.3380033984780312, Validation Loss: -0.3273613154888153
Epoch: 96, Train Loss: -0.3327329950200187, Validation Loss: -0.3272901475429535
Epoch: 97, Train Loss: -0.3352205173836814, Validation Loss: -0.3272937834262848
Epoch: 98, Train Loss: -0.33357301188839805, Validation Loss: -0.32722583413124084
Epoch: 99, Train Loss: -0.33271011230018405, Validation Loss: -0.32716360688209534

Epoch: 0, Train Loss: -0.3327140357759264, Validation Loss: -0.3246105909347534
Epoch: 1, Train Loss: -0.33283855352136826, Validation Loss: -0.3185702860355377
Epoch: 2, Train Loss: -0.33721782465775807, Validation Loss: -0.31301549077033997
Epoch: 3, Train Loss: -0.33766226338015665, Validation Loss: -0.30875474214553833
Epoch: 4, Train Loss: -0.3398036373986138, Validation Loss: -0.305350661277771
Epoch: 5, Train Loss: -0.3400837812158797, Validation Loss: -0.30323657393455505
Epoch: 6, Train Loss: -0.34218927125136056, Validation Loss: -0.30154648423194885
Epoch: 7, Train Loss: -0.34327051407761044, Validation Loss: -0.30049920082092285
Epoch: 8, Train Loss: -0.34541451434294385, Validation Loss: -0.3002808690071106
Epoch: 9, Train Loss: -0.34478569096989103, Validation Loss: -0.30014553666114807
Epoch: 10, Train Loss: -0.34521554973390367, Validation Loss: -0.29978635907173157
Epoch: 11, Train Loss: -0.34406477510929107, Validation Loss: -0.29923635721206665
Epoch: 12, Train Loss: -0.3426170067654716, Validation Loss: -0.298607736825943
Epoch: 13, Train Loss: -0.34512558546331196, Validation Loss: -0.2983783483505249
Epoch: 14, Train Loss: -0.34570345679918923, Validation Loss: -0.2983257472515106
Epoch: 15, Train Loss: -0.34551304827133816, Validation Loss: -0.29827621579170227
Epoch: 16, Train Loss: -0.34436712894174787, Validation Loss: -0.29803597927093506
Epoch: 17, Train Loss: -0.34510743154419793, Validation Loss: -0.29790517687797546
Epoch: 18, Train Loss: -0.34521325512064827, Validation Loss: -0.29780349135398865
Epoch: 19, Train Loss: -0.34459667868084376, Validation Loss: -0.2976668179035187
Epoch: 20, Train Loss: -0.3450224194261763, Validation Loss: -0.29751408100128174
Epoch: 21, Train Loss: -0.3448016463054551, Validation Loss: -0.2974212169647217
Epoch: 22, Train Loss: -0.3455355727010303, Validation Loss: -0.29739564657211304
Epoch: 23, Train Loss: -0.345400679939323, Validation Loss: -0.29736366868019104
Epoch: 24, Train Loss: -0.3452828491727511, Validation Loss: -0.2973364293575287
Epoch: 25, Train Loss: -0.34521838078896205, Validation Loss: -0.29726916551589966
Epoch: 26, Train Loss: -0.3454351873861419, Validation Loss: -0.29724761843681335
Epoch: 27, Train Loss: -0.3451089128851891, Validation Loss: -0.2971971333026886
Epoch: 28, Train Loss: -0.3453499408231841, Validation Loss: -0.29715120792388916
Epoch: 29, Train Loss: -0.3449774516953362, Validation Loss: -0.2970820367336273
Epoch: 30, Train Loss: -0.3451236401995023, Validation Loss: -0.2970413863658905
Epoch: 31, Train Loss: -0.3452047944068909, Validation Loss: -0.297002375125885
Epoch: 32, Train Loss: -0.3452111769053671, Validation Loss: -0.2969711422920227
Epoch: 33, Train Loss: -0.3452295617924796, Validation Loss: -0.29693931341171265
Epoch: 34, Train Loss: -0.3454777023858494, Validation Loss: -0.2969329059123993
Epoch: 35, Train Loss: -0.34558606694142024, Validation Loss: -0.296932578086853
Epoch: 36, Train Loss: -0.34543379611439173, Validation Loss: -0.29691702127456665
Epoch: 37, Train Loss: -0.34540203395817015, Validation Loss: -0.29690858721733093
Epoch: 38, Train Loss: -0.3454569117890464, Validation Loss: -0.2968992292881012
Epoch: 39, Train Loss: -0.34549193845854864, Validation Loss: -0.2968904376029968
Epoch: 40, Train Loss: -0.3454905812939008, Validation Loss: -0.2968829572200775
Epoch: 41, Train Loss: -0.3454303786158562, Validation Loss: -0.2968713045120239
Epoch: 42, Train Loss: -0.34545019037193725, Validation Loss: -0.29686257243156433
Epoch: 43, Train Loss: -0.3454107478260994, Validation Loss: -0.2968508303165436
Epoch: 44, Train Loss: -0.34547808534569213, Validation Loss: -0.2968420386314392
Epoch: 45, Train Loss: -0.3453743855158488, Validation Loss: -0.29683083295822144
Epoch: 46, Train Loss: -0.3455985731548733, Validation Loss: -0.29682859778404236
Epoch: 47, Train Loss: -0.34545811629957623, Validation Loss: -0.29682403802871704
Epoch: 48, Train Loss: -0.3455013533433278, Validation Loss: -0.2968146800994873
Epoch: 49, Train Loss: -0.34549854000409447, Validation Loss: -0.29681310057640076
Epoch: 50, Train Loss: -0.34551164623763825, Validation Loss: -0.29680970311164856
Epoch: 51, Train Loss: -0.3454903619156943, Validation Loss: -0.2968041002750397
Epoch: 52, Train Loss: -0.34556718601120845, Validation Loss: -0.2968041002750397
Epoch: 53, Train Loss: -0.34531268742349414, Validation Loss: -0.29678669571876526
Epoch: 54, Train Loss: -0.34555903474489846, Validation Loss: -0.29678529500961304
Epoch: 55, Train Loss: -0.345569370355871, Validation Loss: -0.2967846989631653
Epoch: 56, Train Loss: -0.34556544952922397, Validation Loss: -0.29678553342819214
Epoch: 57, Train Loss: -0.3455358174112108, Validation Loss: -0.29678478837013245
Epoch: 58, Train Loss: -0.3455087234576543, Validation Loss: -0.2967800498008728
Epoch: 59, Train Loss: -0.34560967485109967, Validation Loss: -0.29678305983543396
Epoch: 60, Train Loss: -0.3455031689670351, Validation Loss: -0.29678046703338623
Epoch: 61, Train Loss: -0.34547884613275526, Validation Loss: -0.2967751622200012
Epoch: 62, Train Loss: -0.34545084834098816, Validation Loss: -0.2967676818370819
Epoch: 63, Train Loss: -0.3454838345448176, Validation Loss: -0.2967621088027954
Epoch: 64, Train Loss: -0.3455121397972107, Validation Loss: -0.2967582941055298
Epoch: 65, Train Loss: -0.3454482280545764, Validation Loss: -0.29675087332725525
Epoch: 66, Train Loss: -0.34551133198870554, Validation Loss: -0.29674872756004333
Epoch: 67, Train Loss: -0.34548345820771326, Validation Loss: -0.29674410820007324
Epoch: 68, Train Loss: -0.34554359316825867, Validation Loss: -0.2967410981655121
Epoch: 69, Train Loss: -0.34553591161966324, Validation Loss: -0.29674088954925537
Epoch: 70, Train Loss: -0.3455128081970745, Validation Loss: -0.296737939119339
Epoch: 71, Train Loss: -0.34551510049237144, Validation Loss: -0.2967347204685211
Epoch: 72, Train Loss: -0.3454829735888375, Validation Loss: -0.2967313528060913
Epoch: 73, Train Loss: -0.3455048354135619, Validation Loss: -0.2967275381088257
Epoch: 74, Train Loss: -0.3455431820617782, Validation Loss: -0.296726793050766
Epoch: 75, Train Loss: -0.34552242789003584, Validation Loss: -0.2967250645160675
Epoch: 76, Train Loss: -0.3455385857158237, Validation Loss: -0.2967234253883362
Epoch: 77, Train Loss: -0.34549898107846577, Validation Loss: -0.2967204749584198
Epoch: 78, Train Loss: -0.34551111194822526, Validation Loss: -0.2967180609703064
Epoch: 79, Train Loss: -0.3455452498462465, Validation Loss: -0.29671743512153625
Epoch: 80, Train Loss: -0.34556657986508477, Validation Loss: -0.2967172861099243
Epoch: 81, Train Loss: -0.34557211465305754, Validation Loss: -0.2967180013656616
Epoch: 82, Train Loss: -0.34551981025271944, Validation Loss: -0.2967167794704437
Epoch: 83, Train Loss: -0.3455461319949892, Validation Loss: -0.2967151999473572
Epoch: 84, Train Loss: -0.34545965509282217, Validation Loss: -0.2967107892036438
Epoch: 85, Train Loss: -0.34555662953191335, Validation Loss: -0.2967096269130707
Epoch: 86, Train Loss: -0.34554037269618776, Validation Loss: -0.2967090308666229
Epoch: 87, Train Loss: -0.3455351033144527, Validation Loss: -0.2967075705528259
Epoch: 88, Train Loss: -0.34553838703367445, Validation Loss: -0.29670658707618713
Epoch: 89, Train Loss: -0.3455261116226514, Validation Loss: -0.2967056930065155
Epoch: 90, Train Loss: -0.3455273288819525, Validation Loss: -0.2967037856578827
Epoch: 91, Train Loss: -0.345533007548915, Validation Loss: -0.2967027723789215
Epoch: 92, Train Loss: -0.34554428143633736, Validation Loss: -0.2967020869255066
Epoch: 93, Train Loss: -0.3455319373144044, Validation Loss: -0.2967010736465454
Epoch: 94, Train Loss: -0.34551156494352553, Validation Loss: -0.29669898748397827
Epoch: 95, Train Loss: -0.3455265329943763, Validation Loss: -0.29669737815856934
Epoch: 96, Train Loss: -0.345537758535809, Validation Loss: -0.2966965138912201
Epoch: 97, Train Loss: -0.3455324169662264, Validation Loss: -0.29669564962387085
Epoch: 98, Train Loss: -0.3455475057164828, Validation Loss: -0.2966945767402649
Epoch: 99, Train Loss: -0.3455536252922482, Validation Loss: -0.29669469594955444


Epoch: 0, Train Loss: -0.3346077799797058, Validation Loss: -0.33079877495765686
Epoch: 1, Train Loss: -0.33155829509099327, Validation Loss: -0.3278968930244446
Epoch: 2, Train Loss: -0.3396656076113383, Validation Loss: -0.3258121609687805
Epoch: 3, Train Loss: -0.33547625607914394, Validation Loss: -0.3235189914703369
Epoch: 4, Train Loss: -0.3414130065176222, Validation Loss: -0.32106253504753113
Epoch: 5, Train Loss: -0.338397803902626, Validation Loss: -0.31876304745674133
Epoch: 6, Train Loss: -0.33969891369342803, Validation Loss: -0.3174741864204407
Epoch: 7, Train Loss: -0.3384100205368466, Validation Loss: -0.31624406576156616
Epoch: 8, Train Loss: -0.33459535539150237, Validation Loss: -0.3142666220664978
Epoch: 9, Train Loss: -0.33874095247851477, Validation Loss: -0.3129514455795288
Epoch: 10, Train Loss: -0.3384630368815528, Validation Loss: -0.3118444085121155
Epoch: 11, Train Loss: -0.33863682515091365, Validation Loss: -0.3107951581478119
Epoch: 12, Train Loss: -0.3416705416308509, Validation Loss: -0.31043028831481934
Epoch: 13, Train Loss: -0.3403599341710409, Validation Loss: -0.3100871741771698
Epoch: 14, Train Loss: -0.341056583987342, Validation Loss: -0.3097509741783142
Epoch: 15, Train Loss: -0.340665399034818, Validation Loss: -0.309361070394516
Epoch: 16, Train Loss: -0.34130944775210487, Validation Loss: -0.3090832829475403
Epoch: 17, Train Loss: -0.34147336284319557, Validation Loss: -0.3088296353816986
Epoch: 18, Train Loss: -0.34281450013319653, Validation Loss: -0.3089582324028015
Epoch: 19, Train Loss: -0.34175196091334026, Validation Loss: -0.30884525179862976
Epoch: 20, Train Loss: -0.3425404555267758, Validation Loss: -0.308794766664505
Epoch: 21, Train Loss: -0.3406110829777188, Validation Loss: -0.3086555600166321
Epoch: 22, Train Loss: -0.3413230091333389, Validation Loss: -0.30823785066604614
Epoch: 23, Train Loss: -0.34138117366366916, Validation Loss: -0.3081101179122925
Epoch: 24, Train Loss: -0.34107357097996605, Validation Loss: -0.30790451169013977
Epoch: 25, Train Loss: -0.3420495304796431, Validation Loss: -0.3078726828098297
Epoch: 26, Train Loss: -0.3414755109283659, Validation Loss: -0.30776485800743103
Epoch: 27, Train Loss: -0.34174784620602927, Validation Loss: -0.30766451358795166
Epoch: 28, Train Loss: -0.34213113851017424, Validation Loss: -0.3076488971710205
Epoch: 29, Train Loss: -0.34156779448191327, Validation Loss: -0.3075665831565857
Epoch: 30, Train Loss: -0.3420975628826353, Validation Loss: -0.30750998854637146
Epoch: 31, Train Loss: -0.34169058038128747, Validation Loss: -0.30744993686676025
Epoch: 32, Train Loss: -0.3418051726288266, Validation Loss: -0.3073723018169403
Epoch: 33, Train Loss: -0.34226558605829877, Validation Loss: -0.30736416578292847
Epoch: 34, Train Loss: -0.34169597956869335, Validation Loss: -0.30729955434799194
Epoch: 35, Train Loss: -0.3417004426320394, Validation Loss: -0.30723661184310913
Epoch: 36, Train Loss: -0.3421715239683787, Validation Loss: -0.30721232295036316
Epoch: 37, Train Loss: -0.34182538588841754, Validation Loss: -0.30718502402305603
Epoch: 38, Train Loss: -0.3418293615182241, Validation Loss: -0.30713382363319397
Epoch: 39, Train Loss: -0.342111047440105, Validation Loss: -0.30711567401885986
Epoch: 40, Train Loss: -0.3421663694911533, Validation Loss: -0.30710312724113464
Epoch: 41, Train Loss: -0.3415336585707135, Validation Loss: -0.30703604221343994
Epoch: 42, Train Loss: -0.3419490863879522, Validation Loss: -0.3070127069950104
Epoch: 43, Train Loss: -0.34223006169001263, Validation Loss: -0.3070090115070343
Epoch: 44, Train Loss: -0.3419111768404643, Validation Loss: -0.3069867491722107
Epoch: 45, Train Loss: -0.3422402663363351, Validation Loss: -0.30697932839393616
Epoch: 46, Train Loss: -0.34221731589900123, Validation Loss: -0.306976854801178
Epoch: 47, Train Loss: -0.34211988515324065, Validation Loss: -0.3069724142551422
Epoch: 48, Train Loss: -0.34230519433816275, Validation Loss: -0.3069716989994049
Epoch: 49, Train Loss: -0.34211616449885895, Validation Loss: -0.3069620430469513
Epoch: 50, Train Loss: -0.3417879190709856, Validation Loss: -0.30693140625953674
Epoch: 51, Train Loss: -0.342036654220687, Validation Loss: -0.3069142699241638
Epoch: 52, Train Loss: -0.3419300648901198, Validation Loss: -0.3068947196006775
Epoch: 53, Train Loss: -0.3420408758852217, Validation Loss: -0.30687734484672546
Epoch: 54, Train Loss: -0.34216471678680843, Validation Loss: -0.30687183141708374
Epoch: 55, Train Loss: -0.34194609655274283, Validation Loss: -0.30685535073280334
Epoch: 56, Train Loss: -0.34210872848828633, Validation Loss: -0.3068465292453766
Epoch: 57, Train Loss: -0.34209292464786106, Validation Loss: -0.30683526396751404
Epoch: 58, Train Loss: -0.3420775615506702, Validation Loss: -0.30682870745658875
Epoch: 59, Train Loss: -0.34201105799939896, Validation Loss: -0.30681726336479187
Epoch: 60, Train Loss: -0.3420993725458781, Validation Loss: -0.3068067133426666
Epoch: 61, Train Loss: -0.34207090901003945, Validation Loss: -0.30679869651794434
Epoch: 62, Train Loss: -0.3421774036354489, Validation Loss: -0.3067954182624817
Epoch: 63, Train Loss: -0.3421578152312173, Validation Loss: -0.30679166316986084
Epoch: 64, Train Loss: -0.34213209549585977, Validation Loss: -0.30678850412368774
Epoch: 65, Train Loss: -0.34210767414834764, Validation Loss: -0.3067818284034729
Epoch: 66, Train Loss: -0.3421233051353031, Validation Loss: -0.30677559971809387
Epoch: 67, Train Loss: -0.34212185574902426, Validation Loss: -0.3067689538002014
Epoch: 68, Train Loss: -0.3420819130208757, Validation Loss: -0.3067629635334015
Epoch: 69, Train Loss: -0.34223445554574333, Validation Loss: -0.30676135420799255
Epoch: 70, Train Loss: -0.3422215610742569, Validation Loss: -0.30676183104515076
Epoch: 71, Train Loss: -0.34220364921622803, Validation Loss: -0.3067610263824463
Epoch: 72, Train Loss: -0.34217436412970226, Validation Loss: -0.3067576289176941
Epoch: 73, Train Loss: -0.3421581096119351, Validation Loss: -0.3067561388015747
Epoch: 74, Train Loss: -0.34223049415482415, Validation Loss: -0.3067535161972046
Epoch: 75, Train Loss: -0.3421257634957631, Validation Loss: -0.30675002932548523
Epoch: 76, Train Loss: -0.34213529229164125, Validation Loss: -0.3067462146282196
Epoch: 77, Train Loss: -0.34219537178675336, Validation Loss: -0.3067443370819092
Epoch: 78, Train Loss: -0.3422613243261973, Validation Loss: -0.30674657225608826
Epoch: 79, Train Loss: -0.34217610127396053, Validation Loss: -0.3067428469657898
Epoch: 80, Train Loss: -0.34218279586897954, Validation Loss: -0.3067411184310913
Epoch: 81, Train Loss: -0.3422465529706743, Validation Loss: -0.30674245953559875
Epoch: 82, Train Loss: -0.34217350449826983, Validation Loss: -0.3067384362220764
Epoch: 83, Train Loss: -0.3422583712471856, Validation Loss: -0.30673977732658386
Epoch: 84, Train Loss: -0.3421635299921036, Validation Loss: -0.30673718452453613
Epoch: 85, Train Loss: -0.3421164360311296, Validation Loss: -0.306733101606369
Epoch: 86, Train Loss: -0.3421874927149879, Validation Loss: -0.30673035979270935
Epoch: 87, Train Loss: -0.3421825779808892, Validation Loss: -0.3067284822463989
Epoch: 88, Train Loss: -0.3422523905833562, Validation Loss: -0.30673032999038696
Epoch: 89, Train Loss: -0.34223029249244263, Validation Loss: -0.3067297637462616
Epoch: 90, Train Loss: -0.34214218623108333, Validation Loss: -0.30672726035118103
Epoch: 91, Train Loss: -0.3421533445517222, Validation Loss: -0.3067231774330139
Epoch: 92, Train Loss: -0.34217823247114815, Validation Loss: -0.30672088265419006
Epoch: 93, Train Loss: -0.34221373233530256, Validation Loss: -0.30672043561935425
Epoch: 94, Train Loss: -0.34220006002320186, Validation Loss: -0.3067188560962677
Epoch: 95, Train Loss: -0.34216979841391243, Validation Loss: -0.3067170977592468
Epoch: 96, Train Loss: -0.34221876131163703, Validation Loss: -0.3067163825035095
Epoch: 97, Train Loss: -0.34218762318293255, Validation Loss: -0.30671432614326477
Epoch: 98, Train Loss: -0.3421808491150538, Validation Loss: -0.3067125082015991
Epoch: 99, Train Loss: -0.3422381467289395, Validation Loss: -0.30671319365501404



9 layers, dropout, 500 neurons, sigmoid, 0.0005 learning rate
Epoch: 0, Train Loss: -0.3264005336496565, Validation Loss: -0.33053848147392273
Epoch: 1, Train Loss: -0.3335965282387204, Validation Loss: -0.3302837312221527
Epoch: 2, Train Loss: -0.33366343047883773, Validation Loss: -0.33014538884162903
Epoch: 3, Train Loss: -0.3338929797212283, Validation Loss: -0.3300791382789612
Epoch: 4, Train Loss: -0.33455313990513486, Validation Loss: -0.3300803303718567
Epoch: 5, Train Loss: -0.3340361507402526, Validation Loss: -0.33005499839782715
Epoch: 6, Train Loss: -0.3342985494269265, Validation Loss: -0.3300352990627289
Epoch: 7, Train Loss: -0.3344174399971962, Validation Loss: -0.33003106713294983
Epoch: 8, Train Loss: -0.3343217796749539, Validation Loss: -0.3300284445285797
Epoch: 9, Train Loss: -0.33444638136360383, Validation Loss: -0.3300279378890991
Epoch: 10, Train Loss: -0.3344446339541011, Validation Loss: -0.3300260007381439
Epoch: 11, Train Loss: -0.33430559519264436, Validation Loss: -0.33002111315727234
Epoch: 12, Train Loss: -0.33438197076320647, Validation Loss: -0.3300187587738037
Epoch: 13, Train Loss: -0.3344441422157817, Validation Loss: -0.33001843094825745
Epoch: 14, Train Loss: -0.3342854243185785, Validation Loss: -0.3300153315067291
Epoch: 15, Train Loss: -0.33442155420780184, Validation Loss: -0.33001258969306946
Epoch: 16, Train Loss: -0.3344317230913374, Validation Loss: -0.33001309633255005
Epoch: 17, Train Loss: -0.3343713783555561, Validation Loss: -0.3300103545188904
Epoch: 18, Train Loss: -0.33436105648676556, Validation Loss: -0.33000844717025757
Epoch: 19, Train Loss: -0.3344259922703107, Validation Loss: -0.3300078213214874
Epoch: 20, Train Loss: -0.334483260081874, Validation Loss: -0.3300081491470337
Epoch: 21, Train Loss: -0.33443391389316984, Validation Loss: -0.3300080895423889
Epoch: 22, Train Loss: -0.3343715214067035, Validation Loss: -0.33000680804252625
Epoch: 23, Train Loss: -0.3344401003585921, Validation Loss: -0.3300066590309143
Epoch: 24, Train Loss: -0.3344668585393164, Validation Loss: -0.33000701665878296
Epoch: 25, Train Loss: -0.33441198368867237, Validation Loss: -0.33000707626342773
Epoch: 26, Train Loss: -0.33439624541335633, Validation Loss: -0.330005407333374
Epoch: 27, Train Loss: -0.3344573414987988, Validation Loss: -0.3300055265426636
Epoch: 28, Train Loss: -0.33441150420241883, Validation Loss: -0.3300049602985382
Epoch: 29, Train Loss: -0.3343987825844023, Validation Loss: -0.3300043046474457
Epoch: 30, Train Loss: -0.33442878392007613, Validation Loss: -0.330003947019577
Epoch: 31, Train Loss: -0.3344474426574177, Validation Loss: -0.33000385761260986
Epoch: 32, Train Loss: -0.33446062356233597, Validation Loss: -0.33000391721725464
Epoch: 33, Train Loss: -0.3344330353869332, Validation Loss: -0.33000385761260986
Epoch: 34, Train Loss: -0.3344443084465133, Validation Loss: -0.33000388741493225
Epoch: 35, Train Loss: -0.33447057041856976, Validation Loss: -0.3300040364265442
Epoch: 36, Train Loss: -0.3344330723086993, Validation Loss: -0.33000409603118896
Epoch: 37, Train Loss: -0.3344275991121928, Validation Loss: -0.33000385761260986
Epoch: 38, Train Loss: -0.3344248250126839, Validation Loss: -0.33000361919403076
Epoch: 39, Train Loss: -0.3344495862722397, Validation Loss: -0.3300034999847412
Epoch: 40, Train Loss: -0.33445139014058645, Validation Loss: -0.330003559589386
Epoch: 41, Train Loss: -0.3344594289859136, Validation Loss: -0.3300037980079651
Epoch: 42, Train Loss: -0.334439969725079, Validation Loss: -0.33000361919403076
Epoch: 43, Train Loss: -0.33442669841978284, Validation Loss: -0.3300034999847412
Epoch: 44, Train Loss: -0.3344220797220866, Validation Loss: -0.33000314235687256
Epoch: 45, Train Loss: -0.33445408476723565, Validation Loss: -0.330003023147583
Epoch: 46, Train Loss: -0.33443383309576247, Validation Loss: -0.3300029933452606
Epoch: 47, Train Loss: -0.334420944750309, Validation Loss: -0.3300026059150696
Epoch: 48, Train Loss: -0.33444373392396504, Validation Loss: -0.33000248670578003
Epoch: 49, Train Loss: -0.33444918973578347, Validation Loss: -0.3300025165081024
Epoch: 50, Train Loss: -0.33443304267194535, Validation Loss: -0.3300026059150696
Epoch: 51, Train Loss: -0.33442715538872614, Validation Loss: -0.3300021290779114
Epoch: 52, Train Loss: -0.33445962220430375, Validation Loss: -0.3300022482872009
Epoch: 53, Train Loss: -0.3344347005089124, Validation Loss: -0.33000218868255615
Epoch: 54, Train Loss: -0.3344213777118259, Validation Loss: -0.3300018310546875
Epoch: 55, Train Loss: -0.33445064425468446, Validation Loss: -0.33000192046165466
Epoch: 56, Train Loss: -0.3344435041149457, Validation Loss: -0.33000195026397705
Epoch: 57, Train Loss: -0.3344289186928007, Validation Loss: -0.3300017714500427
Epoch: 58, Train Loss: -0.3344389700227314, Validation Loss: -0.3300016522407532
Epoch: 59, Train Loss: -0.33443587803178365, Validation Loss: -0.3300015330314636
Epoch: 60, Train Loss: -0.33444365047746233, Validation Loss: -0.3300015330314636
Epoch: 61, Train Loss: -0.33444558862182827, Validation Loss: -0.33000147342681885
Epoch: 62, Train Loss: -0.33444305939806834, Validation Loss: -0.3300015330314636
Epoch: 63, Train Loss: -0.33444265342421003, Validation Loss: -0.33000150322914124
Epoch: 64, Train Loss: -0.33443561726146276, Validation Loss: -0.3300013840198517
Epoch: 65, Train Loss: -0.3344395289818446, Validation Loss: -0.33000126481056213
Epoch: 66, Train Loss: -0.33444690141412947, Validation Loss: -0.33000126481056213
Epoch: 67, Train Loss: -0.33444631579849454, Validation Loss: -0.3300012946128845
Epoch: 68, Train Loss: -0.3344343930482864, Validation Loss: -0.33000120520591736
Epoch: 69, Train Loss: -0.3344517866770426, Validation Loss: -0.3300012946128845
Epoch: 70, Train Loss: -0.33443864319059585, Validation Loss: -0.3300012946128845
Epoch: 71, Train Loss: -0.33443930049737297, Validation Loss: -0.3300011456012726
Epoch: 72, Train Loss: -0.33444133897622425, Validation Loss: -0.33000120520591736
Epoch: 73, Train Loss: -0.3344446185562346, Validation Loss: -0.3300011456012726
Epoch: 74, Train Loss: -0.3344456747174263, Validation Loss: -0.3300011157989502
Epoch: 75, Train Loss: -0.3344442715247472, Validation Loss: -0.3300011456012726
Epoch: 76, Train Loss: -0.33444726450575724, Validation Loss: -0.3300011456012726
Epoch: 77, Train Loss: -0.3344311343299018, Validation Loss: -0.3300010561943054
Epoch: 78, Train Loss: -0.33444781601428986, Validation Loss: -0.33000099658966064
Epoch: 79, Train Loss: -0.3344396592842208, Validation Loss: -0.33000102639198303
Epoch: 80, Train Loss: -0.33444142407841154, Validation Loss: -0.33000096678733826
Epoch: 81, Train Loss: -0.3344446387555864, Validation Loss: -0.33000099658966064
Epoch: 82, Train Loss: -0.3344439564479722, Validation Loss: -0.33000099658966064
Epoch: 83, Train Loss: -0.33444456077284285, Validation Loss: -0.3300009071826935
Epoch: 84, Train Loss: -0.33444382382763754, Validation Loss: -0.33000096678733826
Epoch: 85, Train Loss: -0.3344438478350639, Validation Loss: -0.33000093698501587
Epoch: 86, Train Loss: -0.33444520433743796, Validation Loss: -0.33000096678733826
Epoch: 87, Train Loss: -0.3344449155860477, Validation Loss: -0.33000102639198303
Epoch: 88, Train Loss: -0.3344372933109601, Validation Loss: -0.3300009071826935
Epoch: 89, Train Loss: -0.3344417631626129, Validation Loss: -0.33000075817108154
Epoch: 90, Train Loss: -0.33444490995672016, Validation Loss: -0.33000078797340393
Epoch: 91, Train Loss: -0.3344503271910879, Validation Loss: -0.3300008177757263
Epoch: 92, Train Loss: -0.3344409132997195, Validation Loss: -0.33000075817108154
Epoch: 93, Train Loss: -0.33444973197248246, Validation Loss: -0.33000099658966064
Epoch: 94, Train Loss: -0.33444256600406436, Validation Loss: -0.33000093698501587
Epoch: 95, Train Loss: -0.33444193601608274, Validation Loss: -0.3300008177757263
Epoch: 96, Train Loss: -0.3344496821363767, Validation Loss: -0.3300009071826935
Epoch: 97, Train Loss: -0.33443752080202105, Validation Loss: -0.33000078797340393
Epoch: 98, Train Loss: -0.3344353291723463, Validation Loss: -0.3300006687641144
Epoch: 99, Train Loss: -0.33444127771589494, Validation Loss: -0.33000069856643677
Epoch: 0, Train Loss: -0.32768994205527835, Validation Loss: -0.32568901777267456

Epoch: 1, Train Loss: -0.3350990018910832, Validation Loss: -0.3241212069988251
Epoch: 2, Train Loss: -0.3367701378133562, Validation Loss: -0.32401955127716064
Epoch: 3, Train Loss: -0.3363605952925152, Validation Loss: -0.3237799406051636
Epoch: 4, Train Loss: -0.33679594844579697, Validation Loss: -0.3238065838813782
Epoch: 5, Train Loss: -0.33634306109613843, Validation Loss: -0.32360395789146423
Epoch: 6, Train Loss: -0.3366176438000467, Validation Loss: -0.3235410153865814
Epoch: 7, Train Loss: -0.33641241507397757, Validation Loss: -0.32347244024276733
Epoch: 8, Train Loss: -0.3367286471856965, Validation Loss: -0.3234688639640808
Epoch: 9, Train Loss: -0.3363035036457909, Validation Loss: -0.32340678572654724
Epoch: 10, Train Loss: -0.3367290837897195, Validation Loss: -0.32338112592697144
Epoch: 11, Train Loss: -0.33668346967962054, Validation Loss: -0.323371946811676
Epoch: 12, Train Loss: -0.33660043511125776, Validation Loss: -0.32336318492889404
Epoch: 13, Train Loss: -0.3365283535586463, Validation Loss: -0.32336995005607605
Epoch: 14, Train Loss: -0.3367249353064431, Validation Loss: -0.32337334752082825
Epoch: 15, Train Loss: -0.33657947348223793, Validation Loss: -0.3233674466609955
Epoch: 16, Train Loss: -0.33655746115578544, Validation Loss: -0.3233608305454254
Epoch: 17, Train Loss: -0.33662593397829266, Validation Loss: -0.3233547508716583
Epoch: 18, Train Loss: -0.3366483160191112, Validation Loss: -0.323353111743927
Epoch: 19, Train Loss: -0.3366665008995268, Validation Loss: -0.3233506977558136
Epoch: 20, Train Loss: -0.3366219621565607, Validation Loss: -0.323346883058548
Epoch: 21, Train Loss: -0.3366593778133392, Validation Loss: -0.3233465850353241
Epoch: 22, Train Loss: -0.3366851243707869, Validation Loss: -0.3233448565006256
Epoch: 23, Train Loss: -0.3366832349035475, Validation Loss: -0.32334548234939575
Epoch: 24, Train Loss: -0.3366463843319151, Validation Loss: -0.32334262132644653
Epoch: 25, Train Loss: -0.33671216236220464, Validation Loss: -0.3233400881290436
Epoch: 26, Train Loss: -0.3366708979010582, Validation Loss: -0.3233334422111511
Epoch: 27, Train Loss: -0.3366551018423504, Validation Loss: -0.32333868741989136
Epoch: 28, Train Loss: -0.33665169295337466, Validation Loss: -0.3233373165130615
Epoch: 29, Train Loss: -0.3366797725359599, Validation Loss: -0.32333704829216003
Epoch: 30, Train Loss: -0.33667261633608075, Validation Loss: -0.3233301341533661
Epoch: 31, Train Loss: -0.33661042849222816, Validation Loss: -0.32333606481552124
Epoch: 32, Train Loss: -0.33665802677472434, Validation Loss: -0.32333436608314514
Epoch: 33, Train Loss: -0.336676471763187, Validation Loss: -0.32333216071128845
Epoch: 34, Train Loss: -0.3366621649927563, Validation Loss: -0.3233323395252228
Epoch: 35, Train Loss: -0.33672295990917417, Validation Loss: -0.32331937551498413
Epoch: 36, Train Loss: -0.33660446024603313, Validation Loss: -0.323321670293808
Epoch: 37, Train Loss: -0.3366483661863539, Validation Loss: -0.3233286142349243
Epoch: 38, Train Loss: -0.33662924766540525, Validation Loss: -0.32333099842071533
Epoch: 39, Train Loss: -0.33670900414387384, Validation Loss: -0.3233274817466736
Epoch: 40, Train Loss: -0.33667408525943754, Validation Loss: -0.3233211934566498
Epoch: 41, Train Loss: -0.3366516661312845, Validation Loss: -0.32332366704940796
Epoch: 42, Train Loss: -0.3367340476976501, Validation Loss: -0.32330095767974854
Epoch: 43, Train Loss: -0.33660669922828673, Validation Loss: -0.323299378156662
Epoch: 44, Train Loss: -0.3367083403799269, Validation Loss: -0.3233013451099396
Epoch: 45, Train Loss: -0.3365623644656605, Validation Loss: -0.3233198821544647
Epoch: 46, Train Loss: -0.3366325914859772, Validation Loss: -0.32332566380500793
Epoch: 47, Train Loss: -0.33661693616045846, Validation Loss: -0.3233306109905243
Epoch: 48, Train Loss: -0.3366850205593639, Validation Loss: -0.32332804799079895
Epoch: 49, Train Loss: -0.3367298172579871, Validation Loss: -0.32332083582878113
Epoch: 50, Train Loss: -0.3366879610551728, Validation Loss: -0.32331469655036926
Epoch: 51, Train Loss: -0.3366835731599066, Validation Loss: -0.3233059048652649
Epoch: 52, Train Loss: -0.33657719757821825, Validation Loss: -0.3233279585838318
Epoch: 53, Train Loss: -0.3366708589924706, Validation Loss: -0.3233269155025482
Epoch: 54, Train Loss: -0.33666907962825565, Validation Loss: -0.3233267068862915
Epoch: 55, Train Loss: -0.33666052255365586, Validation Loss: -0.32332783937454224
Epoch: 56, Train Loss: -0.33666272461414337, Validation Loss: -0.32332780957221985
Epoch: 57, Train Loss: -0.3367563241057926, Validation Loss: -0.3233106732368469
Epoch: 58, Train Loss: -0.33661853786971835, Validation Loss: -0.323318213224411
Epoch: 59, Train Loss: -0.33659973674350313, Validation Loss: -0.323329895734787
Epoch: 60, Train Loss: -0.3366958889696333, Validation Loss: -0.32332614064216614
Epoch: 61, Train Loss: -0.336648242506716, Validation Loss: -0.32332828640937805
Epoch: 62, Train Loss: -0.3366664460963673, Validation Loss: -0.3233276307582855
Epoch: 63, Train Loss: -0.3366671630077892, Validation Loss: -0.3233269453048706
Epoch: 64, Train Loss: -0.33668547322352727, Validation Loss: -0.32332322001457214
Epoch: 65, Train Loss: -0.33666511442926195, Validation Loss: -0.32331782579421997
Epoch: 66, Train Loss: -0.336616321404775, Validation Loss: -0.32332953810691833
Epoch: 67, Train Loss: -0.3366630908515718, Validation Loss: -0.3233293294906616
Epoch: 68, Train Loss: -0.3366412768761317, Validation Loss: -0.32333099842071533
Epoch: 69, Train Loss: -0.33667960498068067, Validation Loss: -0.3233305513858795
Epoch: 70, Train Loss: -0.3366547248429722, Validation Loss: -0.3233313262462616
Epoch: 71, Train Loss: -0.336668984260824, Validation Loss: -0.3233313262462616
Epoch: 72, Train Loss: -0.3366782554321819, Validation Loss: -0.32333052158355713
Epoch: 73, Train Loss: -0.3366654202342033, Validation Loss: -0.32333022356033325
Epoch: 74, Train Loss: -0.33669315427541735, Validation Loss: -0.32332783937454224
Epoch: 75, Train Loss: -0.33667184097899333, Validation Loss: -0.3233254551887512
Epoch: 76, Train Loss: -0.3367006844944424, Validation Loss: -0.32331499457359314
Epoch: 77, Train Loss: -0.3366074711084366, Validation Loss: -0.3233284652233124
Epoch: 78, Train Loss: -0.33666310608386996, Validation Loss: -0.3233291208744049
Epoch: 79, Train Loss: -0.3366401228639815, Validation Loss: -0.3233301639556885
Epoch: 80, Train Loss: -0.3366655313306385, Validation Loss: -0.3233307898044586
Epoch: 81, Train Loss: -0.33665949586364957, Validation Loss: -0.32333141565322876
Epoch: 82, Train Loss: -0.3366590400536855, Validation Loss: -0.32333171367645264
Epoch: 83, Train Loss: -0.33666403591632843, Validation Loss: -0.3233317732810974
Epoch: 84, Train Loss: -0.33666407697730594, Validation Loss: -0.32333189249038696
Epoch: 85, Train Loss: -0.33667369567685657, Validation Loss: -0.32333120703697205
Epoch: 86, Train Loss: -0.3366605351368586, Validation Loss: -0.32333168387413025
Epoch: 87, Train Loss: -0.3366687774658203, Validation Loss: -0.3233315348625183
Epoch: 88, Train Loss: -0.3366824188166194, Validation Loss: -0.3233301639556885
Epoch: 89, Train Loss: -0.33665412929322985, Validation Loss: -0.3233301341533661
Epoch: 90, Train Loss: -0.33667229215304056, Validation Loss: -0.32332950830459595
Epoch: 91, Train Loss: -0.3366754444109069, Validation Loss: -0.32332825660705566
Epoch: 92, Train Loss: -0.3366664260625839, Validation Loss: -0.32332852482795715
Epoch: 93, Train Loss: -0.33666637490193047, Validation Loss: -0.323329359292984
Epoch: 94, Train Loss: -0.33668377614683576, Validation Loss: -0.3233232796192169
Epoch: 95, Train Loss: -0.3367157373163435, Validation Loss: -0.32330188155174255
Epoch: 96, Train Loss: -0.336585791905721, Validation Loss: -0.32332977652549744
Epoch: 97, Train Loss: -0.33666389534870783, Validation Loss: -0.3233303725719452
Epoch: 98, Train Loss: -0.3366744839482837, Validation Loss: -0.3233288526535034
Epoch: 99, Train Loss: -0.3366388017932574, Validation Loss: -0.32333189249038696
Epoch: 0, Train Loss: -0.3354043910900752, Validation Loss: -0.3106066584587097
Epoch: 1, Train Loss: -0.340695587793986, Validation Loss: -0.3055684268474579

Epoch: 2, Train Loss: -0.3426794754134284, Validation Loss: -0.30432698130607605
Epoch: 3, Train Loss: -0.34272531701458825, Validation Loss: -0.30398795008659363
Epoch: 4, Train Loss: -0.34296882152557373, Validation Loss: -0.30378851294517517
Epoch: 5, Train Loss: -0.34307240611977047, Validation Loss: -0.3036401867866516
Epoch: 6, Train Loss: -0.34311717285050286, Validation Loss: -0.3035511076450348
Epoch: 7, Train Loss: -0.3430803351932102, Validation Loss: -0.303499311208725
Epoch: 8, Train Loss: -0.3432929992675781, Validation Loss: -0.30347925424575806
Epoch: 9, Train Loss: -0.34322338104248046, Validation Loss: -0.30345845222473145
Epoch: 10, Train Loss: -0.34331477582454684, Validation Loss: -0.30345356464385986
Epoch: 11, Train Loss: -0.3433093928628498, Validation Loss: -0.30344831943511963
Epoch: 12, Train Loss: -0.34324857393900554, Validation Loss: -0.3034287393093109
Epoch: 13, Train Loss: -0.34334004918734234, Validation Loss: -0.3034265339374542
Epoch: 14, Train Loss: -0.3433157424132029, Validation Loss: -0.30342331528663635
Epoch: 15, Train Loss: -0.3432798309458627, Validation Loss: -0.3034139573574066
Epoch: 16, Train Loss: -0.3432700776391559, Validation Loss: -0.3034020662307739
Epoch: 17, Train Loss: -0.3433422784010569, Validation Loss: -0.3034009337425232
Epoch: 18, Train Loss: -0.34330569042099846, Validation Loss: -0.3033955991268158
Epoch: 19, Train Loss: -0.3432600398858388, Validation Loss: -0.30338624119758606
Epoch: 20, Train Loss: -0.3433327297369639, Validation Loss: -0.3033861815929413
Epoch: 21, Train Loss: -0.3432918813493517, Validation Loss: -0.30338090658187866
Epoch: 22, Train Loss: -0.3433133771022161, Validation Loss: -0.30337727069854736
Epoch: 23, Train Loss: -0.34332520133919187, Validation Loss: -0.3033750653266907
Epoch: 24, Train Loss: -0.3433190302716361, Validation Loss: -0.303372323513031
Epoch: 25, Train Loss: -0.3432971268892288, Validation Loss: -0.3033684194087982
Epoch: 26, Train Loss: -0.34333952797783746, Validation Loss: -0.30336853861808777
Epoch: 27, Train Loss: -0.3432987911833657, Validation Loss: -0.30336469411849976
Epoch: 28, Train Loss: -0.3433367020554013, Validation Loss: -0.3033645749092102
Epoch: 29, Train Loss: -0.34329634971088835, Validation Loss: -0.3033609986305237
Epoch: 30, Train Loss: -0.34332022103998394, Validation Loss: -0.3033594489097595
Epoch: 31, Train Loss: -0.34330902066495683, Validation Loss: -0.3033568263053894
Epoch: 32, Train Loss: -0.3433126995960871, Validation Loss: -0.3033541738986969
Epoch: 33, Train Loss: -0.34331785241762797, Validation Loss: -0.3033532500267029
Epoch: 34, Train Loss: -0.34333060681819916, Validation Loss: -0.3033522367477417
Epoch: 35, Train Loss: -0.343318455086814, Validation Loss: -0.3033515512943268
Epoch: 36, Train Loss: -0.34331317875120376, Validation Loss: -0.30334973335266113
Epoch: 37, Train Loss: -0.34335566461086275, Validation Loss: -0.3033510446548462
Epoch: 38, Train Loss: -0.3433172404766083, Validation Loss: -0.3033508360385895
Epoch: 39, Train Loss: -0.3433198031451967, Validation Loss: -0.3033487796783447
Epoch: 40, Train Loss: -0.3433379547463523, Validation Loss: -0.30334919691085815
Epoch: 41, Train Loss: -0.3433321777317259, Validation Loss: -0.3033488392829895
Epoch: 42, Train Loss: -0.3433199465274811, Validation Loss: -0.30334752798080444
Epoch: 43, Train Loss: -0.34333074622684057, Validation Loss: -0.3033474385738373
Epoch: 44, Train Loss: -0.3433112723959817, Validation Loss: -0.30334633588790894
Epoch: 45, Train Loss: -0.34333413077725305, Validation Loss: -0.30334576964378357
Epoch: 46, Train Loss: -0.3433307197358873, Validation Loss: -0.3033457100391388
Epoch: 47, Train Loss: -0.34332752525806426, Validation Loss: -0.3033451735973358
Epoch: 48, Train Loss: -0.3433438499768575, Validation Loss: -0.30334562063217163
Epoch: 49, Train Loss: -0.3433345804611842, Validation Loss: -0.30334576964378357
Epoch: 50, Train Loss: -0.3433174643251631, Validation Loss: -0.3033449053764343
Epoch: 51, Train Loss: -0.34332149492369757, Validation Loss: -0.30334362387657166
Epoch: 52, Train Loss: -0.34332361320654553, Validation Loss: -0.3033429980278015
Epoch: 53, Train Loss: -0.3433313876390457, Validation Loss: -0.3033428490161896
Epoch: 54, Train Loss: -0.34332881801658205, Validation Loss: -0.30334240198135376
Epoch: 55, Train Loss: -0.34332497649722626, Validation Loss: -0.303341805934906
Epoch: 56, Train Loss: -0.34333060019546086, Validation Loss: -0.3033415377140045
Epoch: 57, Train Loss: -0.34333122041490344, Validation Loss: -0.3033413589000702
Epoch: 58, Train Loss: -0.34333569440576767, Validation Loss: -0.30334147810935974
Epoch: 59, Train Loss: -0.34332554505931007, Validation Loss: -0.30334097146987915
Epoch: 60, Train Loss: -0.34333020117547774, Validation Loss: -0.3033408224582672
Epoch: 61, Train Loss: -0.3433318181170358, Validation Loss: -0.3033405542373657
Epoch: 62, Train Loss: -0.3433279037475586, Validation Loss: -0.3033403754234314
Epoch: 63, Train Loss: -0.34332060350312127, Validation Loss: -0.30333957076072693
Epoch: 64, Train Loss: -0.3433246185382207, Validation Loss: -0.3033391237258911
Epoch: 65, Train Loss: -0.343326919608646, Validation Loss: -0.3033386766910553
Epoch: 66, Train Loss: -0.34332625071207684, Validation Loss: -0.30333834886550903
Epoch: 67, Train Loss: -0.34332752492692736, Validation Loss: -0.30333808064460754
Epoch: 68, Train Loss: -0.34332762559254965, Validation Loss: -0.3033377528190613
Epoch: 69, Train Loss: -0.34333404666847656, Validation Loss: -0.3033377230167389
Epoch: 70, Train Loss: -0.3433306078116099, Validation Loss: -0.30333754420280457
Epoch: 71, Train Loss: -0.343330313762029, Validation Loss: -0.3033373951911926
Epoch: 72, Train Loss: -0.3433308955695894, Validation Loss: -0.30333730578422546
Epoch: 73, Train Loss: -0.3433312306801478, Validation Loss: -0.3033371865749359
Epoch: 74, Train Loss: -0.34333516591125063, Validation Loss: -0.3033372461795807
Epoch: 75, Train Loss: -0.3433325105243259, Validation Loss: -0.3033372461795807
Epoch: 76, Train Loss: -0.34333349333869084, Validation Loss: -0.30333733558654785
Epoch: 77, Train Loss: -0.34333065317736733, Validation Loss: -0.30333712697029114
Epoch: 78, Train Loss: -0.34333181712362504, Validation Loss: -0.3033370077610016
Epoch: 79, Train Loss: -0.3433329724603229, Validation Loss: -0.3033370077610016
Epoch: 80, Train Loss: -0.3433305190669166, Validation Loss: -0.30333688855171204
Epoch: 81, Train Loss: -0.3433354549937778, Validation Loss: -0.3033370077610016
Epoch: 82, Train Loss: -0.34333235853248173, Validation Loss: -0.30333685874938965
Epoch: 83, Train Loss: -0.3433287448353238, Validation Loss: -0.3033367395401001
Epoch: 84, Train Loss: -0.3433314790328344, Validation Loss: -0.3033365309238434
Epoch: 85, Train Loss: -0.34333113133907317, Validation Loss: -0.3033365309238434
Epoch: 86, Train Loss: -0.34333037700917984, Validation Loss: -0.30333632230758667
Epoch: 87, Train Loss: -0.3433335738049613, Validation Loss: -0.3033362925052643
Epoch: 88, Train Loss: -0.34333202573988175, Validation Loss: -0.3033362925052643
Epoch: 89, Train Loss: -0.3433303955528471, Validation Loss: -0.30333608388900757
Epoch: 90, Train Loss: -0.3433306501971351, Validation Loss: -0.3033360242843628
Epoch: 91, Train Loss: -0.3433354655901591, Validation Loss: -0.30333608388900757
Epoch: 92, Train Loss: -0.3433356228801939, Validation Loss: -0.3033360242843628
Epoch: 93, Train Loss: -0.34333079987102083, Validation Loss: -0.3033360540866852
Epoch: 94, Train Loss: -0.34333271318011815, Validation Loss: -0.3033360242843628
Epoch: 95, Train Loss: -0.3433312373028861, Validation Loss: -0.30333587527275085
Epoch: 96, Train Loss: -0.34333264463477664, Validation Loss: -0.3033357858657837
Epoch: 97, Train Loss: -0.34333203898535836, Validation Loss: -0.3033357858657837
Epoch: 98, Train Loss: -0.34333124690585665, Validation Loss: -0.30333569645881653
Epoch: 99, Train Loss: -0.3433309574921926, Validation Loss: -0.303335577249527
Epoch: 0, Train Loss: -0.3275379849804772, Validation Loss: -0.33293405175209045
Epoch: 1, Train Loss: -0.33062774538993833, Validation Loss: -0.326347291469574
Epoch: 2, Train Loss: -0.33169249362415737, Validation Loss: -0.32227823138237

Epoch: 3, Train Loss: -0.3357887589269214, Validation Loss: -0.32106465101242065
Epoch: 4, Train Loss: -0.33781518373224473, Validation Loss: -0.32097238302230835
Epoch: 5, Train Loss: -0.33562778168254426, Validation Loss: -0.320397287607193
Epoch: 6, Train Loss: -0.33763872351911334, Validation Loss: -0.32031911611557007
Epoch: 7, Train Loss: -0.33829744789335464, Validation Loss: -0.3203921616077423
Epoch: 8, Train Loss: -0.33758214513460794, Validation Loss: -0.320341020822525
Epoch: 9, Train Loss: -0.3378542989492416, Validation Loss: -0.3203657269477844
Epoch: 10, Train Loss: -0.33747179938687216, Validation Loss: -0.3202977478504181
Epoch: 11, Train Loss: -0.3380302968952391, Validation Loss: -0.3203124403953552
Epoch: 12, Train Loss: -0.3370423078536987, Validation Loss: -0.3201879858970642
Epoch: 13, Train Loss: -0.33765304817093744, Validation Loss: -0.32016345858573914
Epoch: 14, Train Loss: -0.3376099321577284, Validation Loss: -0.32014375925064087
Epoch: 15, Train Loss: -0.3377348552147547, Validation Loss: -0.32012704014778137
Epoch: 16, Train Loss: -0.3379150801234775, Validation Loss: -0.3201391100883484
Epoch: 17, Train Loss: -0.3376962469683753, Validation Loss: -0.3201289474964142
Epoch: 18, Train Loss: -0.33764499194092223, Validation Loss: -0.3201100826263428
Epoch: 19, Train Loss: -0.3378551185131073, Validation Loss: -0.3201231062412262
Epoch: 20, Train Loss: -0.3377206203010347, Validation Loss: -0.3201093077659607
Epoch: 21, Train Loss: -0.33756575617525314, Validation Loss: -0.3200869858264923
Epoch: 22, Train Loss: -0.33757376107904646, Validation Loss: -0.3200676143169403
Epoch: 23, Train Loss: -0.3376148631175359, Validation Loss: -0.32005491852760315
Epoch: 24, Train Loss: -0.33775066832701367, Validation Loss: -0.32005056738853455
Epoch: 25, Train Loss: -0.3377439796924591, Validation Loss: -0.32004716992378235
Epoch: 26, Train Loss: -0.33778418600559235, Validation Loss: -0.3200477361679077
Epoch: 27, Train Loss: -0.3377672569619285, Validation Loss: -0.3200468122959137
Epoch: 28, Train Loss: -0.3377441922823588, Validation Loss: -0.32004421949386597
Epoch: 29, Train Loss: -0.3377547432978948, Validation Loss: -0.32004058361053467
Epoch: 30, Train Loss: -0.3378374480538898, Validation Loss: -0.32004478573799133
Epoch: 31, Train Loss: -0.3377708865536584, Validation Loss: -0.32004430890083313
Epoch: 32, Train Loss: -0.3377296457688014, Validation Loss: -0.32004114985466003
Epoch: 33, Train Loss: -0.3377423322863049, Validation Loss: -0.32003816962242126
Epoch: 34, Train Loss: -0.33782295054859585, Validation Loss: -0.32004064321517944
Epoch: 35, Train Loss: -0.33775893217987485, Validation Loss: -0.32003915309906006
Epoch: 36, Train Loss: -0.3377553347084257, Validation Loss: -0.3200378119945526
Epoch: 37, Train Loss: -0.3377451224459542, Validation Loss: -0.3200366497039795
Epoch: 38, Train Loss: -0.33777074416478475, Validation Loss: -0.32003462314605713
Epoch: 39, Train Loss: -0.3376675973335902, Validation Loss: -0.32002773880958557
Epoch: 40, Train Loss: -0.337800462047259, Validation Loss: -0.3200276494026184
Epoch: 41, Train Loss: -0.3377893348534902, Validation Loss: -0.3200278580188751
Epoch: 42, Train Loss: -0.33768361310164136, Validation Loss: -0.3200240731239319
Epoch: 43, Train Loss: -0.3377811269627677, Validation Loss: -0.32002294063568115
Epoch: 44, Train Loss: -0.3377678351269828, Validation Loss: -0.3200240731239319
Epoch: 45, Train Loss: -0.3377333879470825, Validation Loss: -0.3200203776359558
Epoch: 46, Train Loss: -0.33772653573089173, Validation Loss: -0.3200177848339081
Epoch: 47, Train Loss: -0.3377187838157018, Validation Loss: -0.3200151026248932
Epoch: 48, Train Loss: -0.3377627495262358, Validation Loss: -0.3200138211250305
Epoch: 49, Train Loss: -0.3377706037627326, Validation Loss: -0.3200134336948395
Epoch: 50, Train Loss: -0.3377565234899521, Validation Loss: -0.3200129568576813
Epoch: 51, Train Loss: -0.3377743151452806, Validation Loss: -0.3200126886367798
Epoch: 52, Train Loss: -0.33777381148603225, Validation Loss: -0.32001230120658875
Epoch: 53, Train Loss: -0.33777253362867565, Validation Loss: -0.3200123906135559
Epoch: 54, Train Loss: -0.33777037428485024, Validation Loss: -0.3200117349624634
Epoch: 55, Train Loss: -0.3377744651503033, Validation Loss: -0.3200116753578186
Epoch: 56, Train Loss: -0.33776906463834977, Validation Loss: -0.32001128792762756
Epoch: 57, Train Loss: -0.33779090543588003, Validation Loss: -0.320011705160141
Epoch: 58, Train Loss: -0.337731702460183, Validation Loss: -0.32001060247421265
Epoch: 59, Train Loss: -0.3377843578656515, Validation Loss: -0.32001009583473206
Epoch: 60, Train Loss: -0.33777279787593417, Validation Loss: -0.32001030445098877
Epoch: 61, Train Loss: -0.33777595890892875, Validation Loss: -0.3200097978115082
Epoch: 62, Train Loss: -0.3377549535698361, Validation Loss: -0.32000914216041565
Epoch: 63, Train Loss: -0.3377507385280397, Validation Loss: -0.3200083076953888
Epoch: 64, Train Loss: -0.337765986389584, Validation Loss: -0.3200076222419739
Epoch: 65, Train Loss: -0.3377598034010993, Validation Loss: -0.3200071156024933
Epoch: 66, Train Loss: -0.33778300848272114, Validation Loss: -0.320006787776947
Epoch: 67, Train Loss: -0.3377842628293567, Validation Loss: -0.3200073540210724
Epoch: 68, Train Loss: -0.3377845780717002, Validation Loss: -0.3200075626373291
Epoch: 69, Train Loss: -0.33778274754683174, Validation Loss: -0.3200078308582306
Epoch: 70, Train Loss: -0.33776753743489585, Validation Loss: -0.3200073540210724
