{'kernel_size': 5, 'conv_out_channels': 5, 'linear_size': 500}, no augmentation
Epoch: 0, Train Loss: -0.8903925741488735, Validation Loss: -0.9578946232795715
Epoch: 1, Train Loss: -0.9681279010772705, Validation Loss: -0.9766244888305664
Epoch: 2, Train Loss: -0.9770706111391385, Validation Loss: -0.9819416403770447
Epoch: 3, Train Loss: -0.9811700644691785, Validation Loss: -0.9832799434661865
Epoch: 4, Train Loss: -0.9838473280866941, Validation Loss: -0.9863901138305664
Epoch: 5, Train Loss: -0.9860902809898059, Validation Loss: -0.9880233407020569
Epoch: 6, Train Loss: -0.9870694716572761, Validation Loss: -0.9856835603713989
Epoch: 7, Train Loss: -0.988528519531091, Validation Loss: -0.9895317554473877
Epoch: 8, Train Loss: -0.988376289665699, Validation Loss: -0.9877215027809143
Epoch: 9, Train Loss: -0.9882959837516149, Validation Loss: -0.9911013245582581
Epoch: 10, Train Loss: -0.9908417308131854, Validation Loss: -0.9896018505096436
Epoch: 11, Train Loss: -0.9904565955003103, Validation Loss: -0.9874708652496338
Epoch: 12, Train Loss: -0.9903679847121238, Validation Loss: -0.9910373687744141
Epoch: 13, Train Loss: -0.9909944396615028, Validation Loss: -0.9911798238754272
Epoch: 14, Train Loss: -0.9915245177547137, Validation Loss: -0.9901233911514282
Epoch: 15, Train Loss: -0.9908704745769501, Validation Loss: -0.991085410118103
Epoch: 16, Train Loss: -0.992306545873483, Validation Loss: -0.9932207465171814
Epoch: 17, Train Loss: -0.9919509229461352, Validation Loss: -0.9932748675346375
Epoch: 18, Train Loss: -0.9924182793299358, Validation Loss: -0.9928620457649231
Epoch: 19, Train Loss: -0.9924039733807246, Validation Loss: -0.9929845333099365
Epoch: 20, Train Loss: -0.9922190157175064, Validation Loss: -0.9931431412696838
Epoch: 21, Train Loss: -0.9923418723543485, Validation Loss: -0.9887234568595886
Epoch: 22, Train Loss: -0.9925520024299621, Validation Loss: -0.9923512935638428
Epoch: 23, Train Loss: -0.9931684055527051, Validation Loss: -0.9901629090309143
Epoch: 24, Train Loss: -0.9932890005310376, Validation Loss: -0.99327152967453
Epoch: 25, Train Loss: -0.9930346569816272, Validation Loss: -0.9943490028381348
Epoch: 26, Train Loss: -0.9942009636561076, Validation Loss: -0.9952356815338135
Epoch: 27, Train Loss: -0.9933158712387085, Validation Loss: -0.9933413863182068
Epoch: 28, Train Loss: -0.9935243571996689, Validation Loss: -0.994181215763092
Epoch: 29, Train Loss: -0.9932164257566134, Validation Loss: -0.9923725724220276
Epoch: 30, Train Loss: -0.9936911916335424, Validation Loss: -0.9905943274497986
Epoch: 31, Train Loss: -0.993952387313048, Validation Loss: -0.9952497482299805
Epoch: 32, Train Loss: -0.9939265254338583, Validation Loss: -0.9937083125114441
Epoch: 33, Train Loss: -0.9942924217979113, Validation Loss: -0.9934415817260742
Epoch: 34, Train Loss: -0.9934488041996956, Validation Loss: -0.9955989718437195
Epoch: 35, Train Loss: -0.9939441563685735, Validation Loss: -0.9953482747077942
Epoch: 36, Train Loss: -0.9946142620444298, Validation Loss: -0.9954692125320435
Epoch: 37, Train Loss: -0.9947067129413287, Validation Loss: -0.9956132173538208
Epoch: 38, Train Loss: -0.9937982904513677, Validation Loss: -0.994900643825531
Epoch: 39, Train Loss: -0.9945552041729291, Validation Loss: -0.9927031397819519
Epoch: 40, Train Loss: -0.9946146405736606, Validation Loss: -0.9943172931671143
Epoch: 41, Train Loss: -0.9941819807489714, Validation Loss: -0.9936240911483765
Epoch: 42, Train Loss: -0.9951928066213925, Validation Loss: -0.995144248008728
Epoch: 43, Train Loss: -0.9939539756377538, Validation Loss: -0.9934561848640442
Epoch: 44, Train Loss: -0.9944068348209063, Validation Loss: -0.9934205412864685
Epoch: 45, Train Loss: -0.9945952946345011, Validation Loss: -0.9939628839492798
Epoch: 46, Train Loss: -0.9941576333642006, Validation Loss: -0.9925700426101685
Epoch: 47, Train Loss: -0.9942924629449844, Validation Loss: -0.9943872094154358
Epoch: 48, Train Loss: -0.9956007600824038, Validation Loss: -0.9954105615615845
Epoch: 49, Train Loss: -0.9950163736144702, Validation Loss: -0.9960443377494812
Epoch: 50, Train Loss: -0.9949817261298497, Validation Loss: -0.9923979640007019
Epoch: 51, Train Loss: -0.9950944313804309, Validation Loss: -0.9953925609588623
Epoch: 52, Train Loss: -0.9950361990729968, Validation Loss: -0.9951061010360718
Epoch: 53, Train Loss: -0.9950615148742994, Validation Loss: -0.9960438013076782
Epoch: 54, Train Loss: -0.9953343198696772, Validation Loss: -0.9953756332397461
Epoch: 55, Train Loss: -0.9946834886670113, Validation Loss: -0.9944596886634827
Epoch: 56, Train Loss: -0.9957647287646929, Validation Loss: -0.9959108829498291
Epoch: 57, Train Loss: -0.9950923929214478, Validation Loss: -0.9961971640586853
Epoch: 58, Train Loss: -0.9958055210312208, Validation Loss: -0.9962562322616577
Epoch: 59, Train Loss: -0.9954192141095797, Validation Loss: -0.9939523935317993
Epoch: 60, Train Loss: -0.9956567578713099, Validation Loss: -0.9963876605033875
Epoch: 61, Train Loss: -0.9955227838754654, Validation Loss: -0.996170699596405
Epoch: 62, Train Loss: -0.99533350755771, Validation Loss: -0.9961055517196655
Epoch: 63, Train Loss: -0.9950019304553668, Validation Loss: -0.9948738217353821
Epoch: 64, Train Loss: -0.9946828762491544, Validation Loss: -0.9956654906272888
Epoch: 65, Train Loss: -0.9953508192698161, Validation Loss: -0.9951778650283813
Epoch: 66, Train Loss: -0.9951974781354268, Validation Loss: -0.9964174032211304
Epoch: 67, Train Loss: -0.9956103118459384, Validation Loss: -0.9946574568748474
Epoch: 68, Train Loss: -0.9950480063756307, Validation Loss: -0.9952288866043091
Epoch: 69, Train Loss: -0.9946174446940422, Validation Loss: -0.9956079125404358
Epoch: 70, Train Loss: -0.9953460127313932, Validation Loss: -0.9951484203338623
Epoch: 71, Train Loss: -0.9955996272961298, Validation Loss: -0.996080219745636
Epoch: 72, Train Loss: -0.9956161813338598, Validation Loss: -0.9961051940917969
Epoch: 73, Train Loss: -0.9958612929582595, Validation Loss: -0.9966799020767212
Epoch: 74, Train Loss: -0.9959765104850133, Validation Loss: -0.9959537386894226
Epoch: 75, Train Loss: -0.9955663848519325, Validation Loss: -0.9954553842544556
Epoch: 76, Train Loss: -0.9957332597970963, Validation Loss: -0.9965060353279114
Epoch: 77, Train Loss: -0.996798555970192, Validation Loss: -0.9964815378189087
Epoch: 78, Train Loss: -0.9945902539491653, Validation Loss: -0.9960155487060547
Epoch: 79, Train Loss: -0.9961273930867514, Validation Loss: -0.9963515400886536
Epoch: 80, Train Loss: -0.9961066471536955, Validation Loss: -0.9961053133010864
Epoch: 81, Train Loss: -0.9959186422626177, Validation Loss: -0.9961448311805725
Epoch: 82, Train Loss: -0.9963324384291967, Validation Loss: -0.9963652491569519
Epoch: 83, Train Loss: -0.996134943207105, Validation Loss: -0.9970930218696594

{'kernel_size': 5, 'conv_out_channels': 5, 'linear_size': 500}: random rotation up to 15 degrees
Epoch: 0, Train Loss: -0.8740198839729031, Validation Loss: -0.9470876455307007
Epoch: 1, Train Loss: -0.9583923447728157, Validation Loss: -0.9594144821166992
Epoch: 2, Train Loss: -0.9671242765784264, Validation Loss: -0.9658542275428772
Epoch: 3, Train Loss: -0.9703384231328964, Validation Loss: -0.9739910960197449
Epoch: 4, Train Loss: -0.9735912433862686, Validation Loss: -0.9752107858657837
Epoch: 5, Train Loss: -0.9756999193628629, Validation Loss: -0.9776700735092163
Epoch: 6, Train Loss: -0.9778465982675553, Validation Loss: -0.9765468835830688
Epoch: 7, Train Loss: -0.9779270140926043, Validation Loss: -0.9787446856498718
Epoch: 8, Train Loss: -0.979772009074688, Validation Loss: -0.9820547699928284
Epoch: 9, Train Loss: -0.9810552506844202, Validation Loss: -0.9802562594413757
Epoch: 10, Train Loss: -0.9815561700065931, Validation Loss: -0.9813649654388428
Epoch: 11, Train Loss: -0.9819367154637972, Validation Loss: -0.9844309687614441
Epoch: 12, Train Loss: -0.9827502032915751, Validation Loss: -0.9849139451980591
Epoch: 13, Train Loss: -0.9828431463241577, Validation Loss: -0.9862253069877625
Epoch: 14, Train Loss: -0.9836110392808914, Validation Loss: -0.9849113821983337
Epoch: 15, Train Loss: -0.9840332863132158, Validation Loss: -0.9847837686538696
Epoch: 16, Train Loss: -0.9843251675367355, Validation Loss: -0.9838044047355652
Epoch: 17, Train Loss: -0.9845301532149315, Validation Loss: -0.9843220710754395
Epoch: 18, Train Loss: -0.9850346309542656, Validation Loss: -0.9854248762130737
Epoch: 19, Train Loss: -0.985234637439251, Validation Loss: -0.9817805290222168
Epoch: 20, Train Loss: -0.9847882198492686, Validation Loss: -0.9868054389953613
Epoch: 21, Train Loss: -0.985900572558244, Validation Loss: -0.9873676896095276
Epoch: 22, Train Loss: -0.9860162998835246, Validation Loss: -0.9873107075691223
Epoch: 23, Train Loss: -0.9863298242290814, Validation Loss: -0.9858567714691162
Epoch: 24, Train Loss: -0.9869316902756691, Validation Loss: -0.9866542220115662
Epoch: 25, Train Loss: -0.9856491285363833, Validation Loss: -0.9857612252235413
Epoch: 26, Train Loss: -0.9858833987514178, Validation Loss: -0.9854415655136108
Epoch: 27, Train Loss: -0.9873662228782971, Validation Loss: -0.9868106245994568
Epoch: 28, Train Loss: -0.986518876294295, Validation Loss: -0.9878175258636475
Epoch: 29, Train Loss: -0.9864216942191124, Validation Loss: -0.9859447479248047
Epoch: 30, Train Loss: -0.9858972986539205, Validation Loss: -0.9884565472602844
Epoch: 31, Train Loss: -0.9871972307960193, Validation Loss: -0.9852929711341858
Epoch: 32, Train Loss: -0.9877155215740204, Validation Loss: -0.9886738061904907
Epoch: 33, Train Loss: -0.9877463174859683, Validation Loss: -0.9882426857948303
Epoch: 34, Train Loss: -0.9876851239999135, Validation Loss: -0.9865726828575134
Epoch: 35, Train Loss: -0.986996769408385, Validation Loss: -0.9854512214660645
Epoch: 36, Train Loss: -0.9879346530834834, Validation Loss: -0.9872994422912598
Epoch: 37, Train Loss: -0.9870458349784216, Validation Loss: -0.9895422458648682
Epoch: 38, Train Loss: -0.9876085833112399, Validation Loss: -0.9885694980621338
Epoch: 39, Train Loss: -0.9872043281197548, Validation Loss: -0.9880064725875854
Epoch: 40, Train Loss: -0.9878977151115735, Validation Loss: -0.9876792430877686
Epoch: 41, Train Loss: -0.9875032964348793, Validation Loss: -0.9880017638206482
Epoch: 42, Train Loss: -0.9873365821838379, Validation Loss: -0.9893287420272827
Epoch: 43, Train Loss: -0.9884974063038826, Validation Loss: -0.9863904714584351
Epoch: 44, Train Loss: -0.9879464789827664, Validation Loss: -0.9873719215393066
Epoch: 45, Train Loss: -0.9870756466984749, Validation Loss: -0.9870507717132568
Epoch: 46, Train Loss: -0.9881408549745878, Validation Loss: -0.9872608184814453
Epoch: 47, Train Loss: -0.9880344882408778, Validation Loss: -0.9887916445732117
Epoch: 48, Train Loss: -0.987333236793677, Validation Loss: -0.9882266521453857
Epoch: 49, Train Loss: -0.9868815373778344, Validation Loss: -0.9881060123443604
Epoch: 50, Train Loss: -0.9875240854620934, Validation Loss: -0.9865471124649048
Epoch: 51, Train Loss: -0.9876241598129273, Validation Loss: -0.9895161986351013
Epoch: 52, Train Loss: -0.988345478951931, Validation Loss: -0.9880751967430115
Epoch: 53, Train Loss: -0.9871917325655619, Validation Loss: -0.9906365275382996
Epoch: 54, Train Loss: -0.9874304062922795, Validation Loss: -0.9873657822608948
Epoch: 55, Train Loss: -0.9877203064958254, Validation Loss: -0.9887751340866089
Epoch: 56, Train Loss: -0.9888341856400172, Validation Loss: -0.9880838990211487
Epoch: 57, Train Loss: -0.9883801813721657, Validation Loss: -0.9900238513946533
Epoch: 58, Train Loss: -0.9890330903331439, Validation Loss: -0.9867582321166992
Epoch: 59, Train Loss: -0.988178700486819, Validation Loss: -0.9883022308349609
Epoch: 60, Train Loss: -0.9893285624980926, Validation Loss: -0.9911379218101501
Epoch: 61, Train Loss: -0.9886266816655794, Validation Loss: -0.9856206774711609
Epoch: 62, Train Loss: -0.987732683022817, Validation Loss: -0.9848251938819885
Epoch: 63, Train Loss: -0.9890506525039673, Validation Loss: -0.9890679121017456
Epoch: 64, Train Loss: -0.9881574217677116, Validation Loss: -0.9889567494392395
Epoch: 65, Train Loss: -0.9884692165056864, Validation Loss: -0.990863025188446
Epoch: 66, Train Loss: -0.9884308290084203, Validation Loss: -0.9901571869850159
Epoch: 67, Train Loss: -0.9889554816285769, Validation Loss: -0.9894346594810486
Epoch: 68, Train Loss: -0.9886484557986259, Validation Loss: -0.9870039820671082
Epoch: 69, Train Loss: -0.9897387835582098, Validation Loss: -0.9890863299369812
Epoch: 70, Train Loss: -0.988179955124855, Validation Loss: -0.9891127943992615
Epoch: 71, Train Loss: -0.9892175019582112, Validation Loss: -0.9882235527038574
Epoch: 72, Train Loss: -0.9884180747866631, Validation Loss: -0.9878405928611755
Epoch: 73, Train Loss: -0.9885244811375936, Validation Loss: -0.9898605942726135
Epoch: 74, Train Loss: -0.9890283046563466, Validation Loss: -0.9801010489463806
Epoch: 75, Train Loss: -0.9876499977906545, Validation Loss: -0.9880765676498413
Epoch: 76, Train Loss: -0.988393509765466, Validation Loss: -0.989772379398346
Epoch: 77, Train Loss: -0.9888016965389251, Validation Loss: -0.988663375377655
Epoch: 78, Train Loss: -0.9885418637792269, Validation Loss: -0.9905731678009033
Epoch: 79, Train Loss: -0.9883937223156293, Validation Loss: -0.9887256622314453
Epoch: 80, Train Loss: -0.9891451117197673, Validation Loss: -0.9881315231323242
Epoch: 81, Train Loss: -0.9878097890615464, Validation Loss: -0.9898526668548584
Epoch: 82, Train Loss: -0.9893813152710597, Validation Loss: -0.9905024170875549
Epoch: 83, Train Loss: -0.9893671684463818, Validation Loss: -0.9891329407691956
Epoch: 84, Train Loss: -0.9895938617984453, Validation Loss: -0.990299642086029
Epoch: 85, Train Loss: -0.9883658452431361, Validation Loss: -0.9886512160301208
Epoch: 86, Train Loss: -0.9887681985497475, Validation Loss: -0.9907371401786804
Epoch: 87, Train Loss: -0.9883728767832121, Validation Loss: -0.9883098602294922
Epoch: 88, Train Loss: -0.9881819821397464, Validation Loss: -0.9866398572921753
Epoch: 89, Train Loss: -0.9890776205460231, Validation Loss: -0.9868623614311218
Epoch: 90, Train Loss: -0.9885704633394877, Validation Loss: -0.9894999861717224
Epoch: 91, Train Loss: -0.9891454149683316, Validation Loss: -0.9889388084411621
Epoch: 92, Train Loss: -0.9894098187088967, Validation Loss: -0.9895915985107422
Epoch: 93, Train Loss: -0.9887166316707929, Validation Loss: -0.9872041940689087
Epoch: 94, Train Loss: -0.9888697170416514, Validation Loss: -0.9887511134147644
Epoch: 95, Train Loss: -0.988744434873263, Validation Loss: -0.9856888055801392
Epoch: 96, Train Loss: -0.9885504530072212, Validation Loss: -0.988901674747467
Epoch: 97, Train Loss: -0.9888589091300964, Validation Loss: -0.9898263812065125
Epoch: 98, Train Loss: -0.989313678363959, Validation Loss: -0.9900757670402527
Epoch: 99, Train Loss: -0.99052707473437, Validation Loss: -0.9908035397529602

{'kernel_size': 5, 'conv_out_channels': 5, 'linear_size': 500} gaussian noise
Epoch: 0, Train Loss: -0.8830556172976891, Validation Loss: -0.9610738754272461
Epoch: 1, Train Loss: -0.9693641307751337, Validation Loss: -0.9745664000511169
Epoch: 2, Train Loss: -0.9774956514040629, Validation Loss: -0.9756055474281311
Epoch: 3, Train Loss: -0.9819653809467952, Validation Loss: -0.9847015738487244
Epoch: 4, Train Loss: -0.9843850330909093, Validation Loss: -0.9878745675086975
Epoch: 5, Train Loss: -0.9868411536812782, Validation Loss: -0.986267626285553
Epoch: 6, Train Loss: -0.9875932010014852, Validation Loss: -0.980516254901886
Epoch: 7, Train Loss: -0.9888831984599431, Validation Loss: -0.989063560962677
Epoch: 8, Train Loss: -0.9891277699271838, Validation Loss: -0.9898488521575928
Epoch: 9, Train Loss: -0.9903773424426715, Validation Loss: -0.9863123893737793
Epoch: 10, Train Loss: -0.9908456504742305, Validation Loss: -0.9914664030075073
Epoch: 11, Train Loss: -0.991184897561868, Validation Loss: -0.9934402704238892
Epoch: 12, Train Loss: -0.9916834187706312, Validation Loss: -0.9887517690658569
Epoch: 13, Train Loss: -0.9921406122843425, Validation Loss: -0.9913994669914246
Epoch: 14, Train Loss: -0.9920190368493398, Validation Loss: -0.9922358393669128
Epoch: 15, Train Loss: -0.9921879168947537, Validation Loss: -0.9936012029647827
Epoch: 16, Train Loss: -0.9927053089141846, Validation Loss: -0.9932799339294434
Epoch: 17, Train Loss: -0.9926060266097386, Validation Loss: -0.9925641417503357
Epoch: 18, Train Loss: -0.9929304961959521, Validation Loss: -0.9924846291542053
Epoch: 19, Train Loss: -0.9935192609826724, Validation Loss: -0.9929043054580688
Epoch: 20, Train Loss: -0.993387487312158, Validation Loss: -0.9929409623146057
Epoch: 21, Train Loss: -0.9933797550797463, Validation Loss: -0.9941299557685852
Epoch: 22, Train Loss: -0.9940069375832875, Validation Loss: -0.9933786392211914
Epoch: 23, Train Loss: -0.9940465426842372, Validation Loss: -0.9913922548294067
Epoch: 24, Train Loss: -0.9937155449390411, Validation Loss: -0.9935199022293091
Epoch: 25, Train Loss: -0.9942397693196933, Validation Loss: -0.9952148199081421
Epoch: 26, Train Loss: -0.9946128462751707, Validation Loss: -0.9951733350753784
Epoch: 27, Train Loss: -0.9941068781415622, Validation Loss: -0.9950809478759766
Epoch: 28, Train Loss: -0.9944868229627609, Validation Loss: -0.9935966730117798
Epoch: 29, Train Loss: -0.9941810635725657, Validation Loss: -0.9948561787605286
Epoch: 30, Train Loss: -0.9950167886813481, Validation Loss: -0.9957743287086487
Epoch: 31, Train Loss: -0.9946458084781965, Validation Loss: -0.9952996969223022
Epoch: 32, Train Loss: -0.9951342490116755, Validation Loss: -0.9924018979072571
Epoch: 33, Train Loss: -0.9947609977324804, Validation Loss: -0.9938944578170776
Epoch: 34, Train Loss: -0.9950691710511843, Validation Loss: -0.994022786617279
Epoch: 35, Train Loss: -0.9953572126229604, Validation Loss: -0.9961445331573486
Epoch: 36, Train Loss: -0.995500299791495, Validation Loss: -0.9943908452987671
Epoch: 37, Train Loss: -0.9954679647684097, Validation Loss: -0.995854377746582
Epoch: 38, Train Loss: -0.994959230641524, Validation Loss: -0.9951298832893372
Epoch: 39, Train Loss: -0.9955426393151283, Validation Loss: -0.9951448440551758
Epoch: 40, Train Loss: -0.995937858859698, Validation Loss: -0.995522677898407
Epoch: 41, Train Loss: -0.9952824559211731, Validation Loss: -0.994721531867981
Epoch: 42, Train Loss: -0.9954915476838747, Validation Loss: -0.996491014957428
Epoch: 43, Train Loss: -0.9952230608661969, Validation Loss: -0.9951214790344238
Epoch: 44, Train Loss: -0.9957888510425885, Validation Loss: -0.9970206618309021
Epoch: 45, Train Loss: -0.9960729026198387, Validation Loss: -0.9960299134254456
Epoch: 46, Train Loss: -0.995528861661752, Validation Loss: -0.9961369633674622
Epoch: 47, Train Loss: -0.9957648892203966, Validation Loss: -0.9959157705307007
Epoch: 48, Train Loss: -0.9954766378601392, Validation Loss: -0.9967237710952759
Epoch: 49, Train Loss: -0.995941768527031, Validation Loss: -0.9968929886817932
Epoch: 50, Train Loss: -0.9961793036063512, Validation Loss: -0.996605396270752
Epoch: 51, Train Loss: -0.9960563409129779, Validation Loss: -0.9961882829666138
Epoch: 52, Train Loss: -0.9960627632935842, Validation Loss: -0.9963492155075073
Epoch: 53, Train Loss: -0.9955353190700214, Validation Loss: -0.9963290691375732
Epoch: 54, Train Loss: -0.9963073886235555, Validation Loss: -0.9968945384025574
Epoch: 55, Train Loss: -0.9963469562927881, Validation Loss: -0.9962009191513062
Epoch: 56, Train Loss: -0.9959144419034323, Validation Loss: -0.9963023066520691
Epoch: 57, Train Loss: -0.9958516824642817, Validation Loss: -0.997117817401886
Epoch: 58, Train Loss: -0.9957139139374097, Validation Loss: -0.9966482520103455
Epoch: 59, Train Loss: -0.9960624907414118, Validation Loss: -0.9968649744987488
Epoch: 60, Train Loss: -0.996063059369723, Validation Loss: -0.9967666864395142
Epoch: 61, Train Loss: -0.9954702247381211, Validation Loss: -0.9968563318252563
Epoch: 62, Train Loss: -0.9962104043364525, Validation Loss: -0.9962184429168701
Epoch: 63, Train Loss: -0.9960473424593608, Validation Loss: -0.9964178800582886
Epoch: 64, Train Loss: -0.9963104262550672, Validation Loss: -0.9974339008331299
Epoch: 65, Train Loss: -0.9959737300276756, Validation Loss: -0.9971609711647034
Epoch: 66, Train Loss: -0.9956370782653491, Validation Loss: -0.9940892457962036
Epoch: 67, Train Loss: -0.996025505622228, Validation Loss: -0.9967175126075745
Epoch: 68, Train Loss: -0.9963723143537839, Validation Loss: -0.9879891872406006
Epoch: 69, Train Loss: -0.9957913283308347, Validation Loss: -0.9969509840011597
Epoch: 70, Train Loss: -0.9963856397271156, Validation Loss: -0.9968975186347961
Epoch: 71, Train Loss: -0.9960251226027806, Validation Loss: -0.9966292977333069
Epoch: 72, Train Loss: -0.9962545744379362, Validation Loss: -0.9970067143440247
Epoch: 73, Train Loss: -0.9957458753387133, Validation Loss: -0.9968259930610657
Epoch: 74, Train Loss: -0.9956055258313815, Validation Loss: -0.9967103004455566
Epoch: 75, Train Loss: -0.996596221268177, Validation Loss: -0.9967951774597168
Epoch: 76, Train Loss: -0.9955945674180985, Validation Loss: -0.9961546063423157
Epoch: 77, Train Loss: -0.9966368616819382, Validation Loss: -0.9961205720901489
Epoch: 78, Train Loss: -0.9965273153980573, Validation Loss: -0.9968892931938171
Epoch: 79, Train Loss: -0.996359970788161, Validation Loss: -0.9970033168792725
Epoch: 80, Train Loss: -0.9965022254983584, Validation Loss: -0.9960120320320129
Epoch: 81, Train Loss: -0.9963994845350583, Validation Loss: -0.9971843361854553
Epoch: 82, Train Loss: -0.9966253109375636, Validation Loss: -0.9967018961906433
Epoch: 83, Train Loss: -0.9955181968013446, Validation Loss: -0.9960499405860901
Epoch: 84, Train Loss: -0.9963384538690249, Validation Loss: -0.9975342750549316
Epoch: 85, Train Loss: -0.9964395539164543, Validation Loss: -0.9972197413444519
Epoch: 86, Train Loss: -0.9965079953074455, Validation Loss: -0.9961292147636414
Epoch: 87, Train Loss: -0.9965647511084874, Validation Loss: -0.9969759583473206
Epoch: 88, Train Loss: -0.996690901140372, Validation Loss: -0.9970719814300537
Epoch: 89, Train Loss: -0.9968178870677948, Validation Loss: -0.997394859790802
Epoch: 90, Train Loss: -0.9959955149491628, Validation Loss: -0.995205819606781
Epoch: 91, Train Loss: -0.9965625432332357, Validation Loss: -0.9972451329231262
Epoch: 92, Train Loss: -0.9967681418259938, Validation Loss: -0.996151328086853
Epoch: 93, Train Loss: -0.9965140787561735, Validation Loss: -0.9970599412918091
Epoch: 94, Train Loss: -0.9966326010425886, Validation Loss: -0.9954087734222412
Epoch: 95, Train Loss: -0.996522391239802, Validation Loss: -0.9948484301567078
Epoch: 96, Train Loss: -0.996852844774723, Validation Loss: -0.9975722432136536
Epoch: 97, Train Loss: -0.9965975828369459, Validation Loss: -0.9968852996826172
Epoch: 98, Train Loss: -0.9971303316950798, Validation Loss: -0.9968834519386292
Epoch: 99, Train Loss: -0.9967300168673198, Validation Loss: -0.9972581267356873

{'kernel_size': 5, 'conv_out_channels': 5, 'linear_size': 500} rotation 15 degree, gaussian noise
Epoch: 0, Train Loss: -0.8230898158053557, Validation Loss: -0.9288526773452759
Epoch: 1, Train Loss: -0.95513512301445, Validation Loss: -0.9639253616333008
Epoch: 2, Train Loss: -0.9642195931871732, Validation Loss: -0.9621785283088684
Epoch: 3, Train Loss: -0.9716175346374512, Validation Loss: -0.972173810005188
Epoch: 4, Train Loss: -0.9739205879370372, Validation Loss: -0.9746850728988647
Epoch: 5, Train Loss: -0.9769066201249759, Validation Loss: -0.9768523573875427
Epoch: 6, Train Loss: -0.9779947476784389, Validation Loss: -0.9776179790496826
Epoch: 7, Train Loss: -0.9787428175806999, Validation Loss: -0.9810363054275513
Epoch: 8, Train Loss: -0.9806776974995931, Validation Loss: -0.982674241065979
Epoch: 9, Train Loss: -0.9806296016772588, Validation Loss: -0.979028582572937
Epoch: 10, Train Loss: -0.9812834273775418, Validation Loss: -0.9834086894989014
Epoch: 11, Train Loss: -0.9818317886789639, Validation Loss: -0.9846426248550415
Epoch: 12, Train Loss: -0.9819615630308787, Validation Loss: -0.9841049909591675
Epoch: 13, Train Loss: -0.9830510034163793, Validation Loss: -0.9839239120483398
Epoch: 14, Train Loss: -0.9827643472750982, Validation Loss: -0.9821622371673584
Epoch: 15, Train Loss: -0.9830739662051201, Validation Loss: -0.9834690690040588
Epoch: 16, Train Loss: -0.9839180916349093, Validation Loss: -0.9800923466682434
Epoch: 17, Train Loss: -0.9843986667195956, Validation Loss: -0.9851604700088501
Epoch: 18, Train Loss: -0.9840265243450801, Validation Loss: -0.9869173169136047
Epoch: 19, Train Loss: -0.983935419857502, Validation Loss: -0.9851865768432617
Epoch: 20, Train Loss: -0.9854974524577459, Validation Loss: -0.9841215014457703
Epoch: 21, Train Loss: -0.9855653241475423, Validation Loss: -0.9861441850662231
Epoch: 22, Train Loss: -0.9851710870464643, Validation Loss: -0.9867847561836243
Epoch: 23, Train Loss: -0.9846136361757915, Validation Loss: -0.9861685037612915
Epoch: 24, Train Loss: -0.9865515891114871, Validation Loss: -0.9883080124855042
Epoch: 25, Train Loss: -0.986057307779789, Validation Loss: -0.9828671813011169
Epoch: 26, Train Loss: -0.9865680795709292, Validation Loss: -0.9818952679634094
Epoch: 27, Train Loss: -0.9859585315783819, Validation Loss: -0.9875121116638184
Epoch: 28, Train Loss: -0.9865037126143773, Validation Loss: -0.9851884841918945
Epoch: 29, Train Loss: -0.9862218231161436, Validation Loss: -0.9860969185829163
Epoch: 30, Train Loss: -0.9861973019838333, Validation Loss: -0.9869404435157776
Epoch: 31, Train Loss: -0.9862072831193606, Validation Loss: -0.9875938296318054
Epoch: 32, Train Loss: -0.9869313069383303, Validation Loss: -0.9868078231811523
Epoch: 33, Train Loss: -0.9869476281007131, Validation Loss: -0.9863888025283813
Epoch: 34, Train Loss: -0.9871176946163177, Validation Loss: -0.9891070127487183
Epoch: 35, Train Loss: -0.9883146755297979, Validation Loss: -0.9887369871139526
Epoch: 36, Train Loss: -0.9870556691288948, Validation Loss: -0.9877220988273621
Epoch: 37, Train Loss: -0.9874456134239833, Validation Loss: -0.9864457249641418
Epoch: 38, Train Loss: -0.9875440967082977, Validation Loss: -0.9884682297706604
Epoch: 39, Train Loss: -0.9861925596197446, Validation Loss: -0.9882122278213501
Epoch: 40, Train Loss: -0.9869342586994171, Validation Loss: -0.9876269698143005
Epoch: 41, Train Loss: -0.9873809223373731, Validation Loss: -0.9881028532981873
Epoch: 42, Train Loss: -0.987888278901577, Validation Loss: -0.9859609007835388
Epoch: 43, Train Loss: -0.9877228834430377, Validation Loss: -0.9876147508621216
Epoch: 44, Train Loss: -0.9875307547251383, Validation Loss: -0.9897249937057495
Epoch: 45, Train Loss: -0.9879130155046781, Validation Loss: -0.9846806526184082
Epoch: 46, Train Loss: -0.9875146876970927, Validation Loss: -0.9858419299125671
Epoch: 47, Train Loss: -0.9874653468132019, Validation Loss: -0.9897351861000061
Epoch: 48, Train Loss: -0.987350157558918, Validation Loss: -0.9897000193595886
Epoch: 49, Train Loss: -0.986953439950943, Validation Loss: -0.9887586832046509
Epoch: 50, Train Loss: -0.9877766698996227, Validation Loss: -0.9881700873374939
Epoch: 51, Train Loss: -0.9885730376640955, Validation Loss: -0.9874038696289062
Epoch: 52, Train Loss: -0.9885084088047346, Validation Loss: -0.9897782206535339
Epoch: 53, Train Loss: -0.988545294602712, Validation Loss: -0.9892523288726807
Epoch: 54, Train Loss: -0.9886797075271606, Validation Loss: -0.9888269901275635
Epoch: 55, Train Loss: -0.988523168126742, Validation Loss: -0.9876390099525452
Epoch: 56, Train Loss: -0.9883309899568558, Validation Loss: -0.9873573184013367
Epoch: 57, Train Loss: -0.9886388864517212, Validation Loss: -0.98899906873703
Epoch: 58, Train Loss: -0.9882743859887123, Validation Loss: -0.9890734553337097
Epoch: 59, Train Loss: -0.9887318979501725, Validation Loss: -0.9893689751625061
Epoch: 60, Train Loss: -0.9890794072747231, Validation Loss: -0.9867150783538818
Epoch: 61, Train Loss: -0.9880982984304428, Validation Loss: -0.9891270399093628
Epoch: 62, Train Loss: -0.9884268719156584, Validation Loss: -0.9876545071601868
Epoch: 63, Train Loss: -0.9881130704283714, Validation Loss: -0.9896025061607361
Epoch: 64, Train Loss: -0.9885500601530075, Validation Loss: -0.9863151907920837
Epoch: 65, Train Loss: -0.9890935690204302, Validation Loss: -0.9892130494117737
Epoch: 66, Train Loss: -0.9888388807376226, Validation Loss: -0.9888196587562561
Epoch: 67, Train Loss: -0.9873061470588048, Validation Loss: -0.988669753074646
Epoch: 68, Train Loss: -0.9887409550746282, Validation Loss: -0.9894903898239136
Epoch: 69, Train Loss: -0.9880654790600141, Validation Loss: -0.989650547504425
Epoch: 70, Train Loss: -0.9875182711482048, Validation Loss: -0.988383948802948
Epoch: 71, Train Loss: -0.9885518802603086, Validation Loss: -0.9892878532409668
Epoch: 72, Train Loss: -0.9891117780208588, Validation Loss: -0.9893280863761902
Epoch: 73, Train Loss: -0.987993543346723, Validation Loss: -0.9880859851837158
Epoch: 74, Train Loss: -0.9879908358454704, Validation Loss: -0.9892147779464722
Epoch: 75, Train Loss: -0.9889641195336978, Validation Loss: -0.987646222114563
Epoch: 76, Train Loss: -0.9877399617036183, Validation Loss: -0.9885383248329163
Epoch: 77, Train Loss: -0.9882919409473737, Validation Loss: -0.9896084070205688
Epoch: 78, Train Loss: -0.9881602296829224, Validation Loss: -0.988490641117096
Epoch: 79, Train Loss: -0.9877463201483091, Validation Loss: -0.9873956441879272
Epoch: 80, Train Loss: -0.9888095860878626, Validation Loss: -0.9906054735183716
Epoch: 81, Train Loss: -0.9891044513781866, Validation Loss: -0.9899928569793701
Epoch: 82, Train Loss: -0.9894672361016273, Validation Loss: -0.9896253943443298
Epoch: 83, Train Loss: -0.9894844651023547, Validation Loss: -0.9890270829200745
Epoch: 84, Train Loss: -0.9887576316396396, Validation Loss: -0.9904899597167969
Epoch: 85, Train Loss: -0.9891062378883362, Validation Loss: -0.9864702224731445
Epoch: 86, Train Loss: -0.9886484983166058, Validation Loss: -0.9885456562042236
Epoch: 87, Train Loss: -0.9888059193094572, Validation Loss: -0.9874251484870911
Epoch: 88, Train Loss: -0.9892820449074109, Validation Loss: -0.989567756652832
Epoch: 89, Train Loss: -0.9893194288015366, Validation Loss: -0.986524224281311
Epoch: 90, Train Loss: -0.9892086084683737, Validation Loss: -0.9871293306350708
Epoch: 91, Train Loss: -0.9887734537323316, Validation Loss: -0.9898708462715149
Epoch: 92, Train Loss: -0.9893747480312983, Validation Loss: -0.9886474609375
Epoch: 93, Train Loss: -0.9885500537355741, Validation Loss: -0.9899815917015076
Epoch: 94, Train Loss: -0.9898986077904701, Validation Loss: -0.9894630312919617
Epoch: 95, Train Loss: -0.9903085881670316, Validation Loss: -0.9902781248092651
Epoch: 96, Train Loss: -0.9903494429787, Validation Loss: -0.99101722240448
Epoch: 97, Train Loss: -0.9901311130523681, Validation Loss: -0.9904177188873291
Epoch: 98, Train Loss: -0.9893199506998062, Validation Loss: -0.9895772337913513
Epoch: 99, Train Loss: -0.9895786801576615, Validation Loss: -0.9889106154441833
