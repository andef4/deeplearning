{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "LABELS = sorted([i[:-4] for i in os.listdir('icons')])\n",
    "NUM_CLASSES = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    \"\"\"\n",
    "    Add gaussian noise to a numpy.ndarray (H x W x C)\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, sigma, random_state=np.random):\n",
    "        self.sigma = sigma\n",
    "        self.mean = mean\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __call__(self, image):\n",
    "        row, col, ch = image.shape\n",
    "        gauss = self.random_state.normal(self.mean, self.sigma, (row, col, ch))\n",
    "        gauss = gauss.reshape(row, col, ch)\n",
    "        image += torch.from_numpy(gauss).float()\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IconsDataset(Dataset):\n",
    "    def __init__(self, directory, labels, transform=None):\n",
    "        self.directory = directory\n",
    "        self.files = os.listdir(directory)[:1000]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        f = self.files[index]\n",
    "        # image\n",
    "        image = Image.open(os.path.join(self.directory, f))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # labels\n",
    "        label = f.split('.')[0].split('_')[1]\n",
    "        label = LABELS.index(label)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    def input_size(self):\n",
    "        return 100 * 100 * 3\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        GaussianNoise(0.01, 0.001),\n",
    "    ])\n",
    "    \n",
    "    d = IconsDataset('images_single/', LABELS, transform=transform)\n",
    "    size = len(d)\n",
    "    train, validate = random_split(d, [int(size * 0.8), int(size * 0.2)])\n",
    "    \n",
    "    loader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "    validation_loader = DataLoader(validate, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return d.input_size(), loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv1(nn.Module):\n",
    "    def __init__(self, kernel_size=5, conv_out_channels=5, linear_size=50):\n",
    "        super().__init__()\n",
    "        if kernel_size % 2 != 1:\n",
    "            raise Exception('Only odd kernel_size are supported')\n",
    "        self.conv_out_channels = conv_out_channels\n",
    "        self.conv1 = nn.Conv2d(3, conv_out_channels, kernel_size=kernel_size)\n",
    "        conv_layer_output_size = int(100 - (kernel_size - 1))\n",
    "        self.pooled_pixels = int(conv_layer_output_size / 2)\n",
    "        self.h1 = nn.Linear(self.pooled_pixels * self.pooled_pixels  * conv_out_channels, linear_size)\n",
    "        self.h2 = nn.Linear(linear_size, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "        x = x.view(-1, self.pooled_pixels * self.pooled_pixels * self.conv_out_channels)\n",
    "\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv2(nn.Module):\n",
    "    def __init__(self, input_size, kernel_size=5, conv_out_channels=5, linear_size=50):\n",
    "        super().__init__()\n",
    "\n",
    "        if kernel_size % 2 != 1:\n",
    "            raise Exception('Only odd kernel_size are supported')\n",
    "        self.conv_out_channels = conv_out_channels\n",
    "        self.conv1 = nn.Conv2d(3, conv_out_channels, kernel_size=kernel_size)\n",
    "        self.conv2 = nn.Conv2d(conv_out_channels, conv_out_channels, kernel_size=kernel_size)\n",
    "        #self.conv3 = nn.Conv2d(conv_out_channels, conv_out_channels, kernel_size=kernel_size)\n",
    "\n",
    "        #conv_layer_output_size = int(input_size - (kernel_size - 1))\n",
    "        x = input_size\n",
    "        x = x - (kernel_size - 1)\n",
    "        x = int(x / 2)\n",
    "        \n",
    "        x = x - (kernel_size - 1)\n",
    "        x = int(x / 2)\n",
    "        \n",
    "        #x = x - (kernel_size - 1)\n",
    "        #x = int(x / 2)\n",
    "        self.pooled_samples = x * x * conv_out_channels\n",
    "\n",
    "        self.h1 = nn.Linear(self.pooled_samples, linear_size)\n",
    "        self.h2 = nn.Linear(linear_size, linear_size)\n",
    "        self.h3 = nn.Linear(linear_size, linear_size)\n",
    "        self.h4 = nn.Linear(linear_size, linear_size)\n",
    "        self.h9 = nn.Linear(linear_size, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        #x = self.conv3(x)\n",
    "        #x = F.relu(x)\n",
    "        #x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "        x = x.view(BATCH_SIZE, self.pooled_samples)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.h2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.h3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.h4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.h9(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def evalulate(model, validation_loader):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    for data, labels in validation_loader:\n",
    "        labels = labels.cuda()\n",
    "        predictions_per_class = model(data.cuda())\n",
    "        _, highest_prediction_class = predictions_per_class.max(1)\n",
    "        loss += F.nll_loss(predictions_per_class, labels)\n",
    "        correct += torch.sum(highest_prediction_class == labels)\n",
    "    return loss/len(validation_loader), correct.item()/len(validation_loader)\n",
    "\n",
    "def learn(model, loader, validation_loader, epochs=30, learning_rate=0.001):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    f = open(f'{datetime.now().isoformat()}.txt', 'w', buffering=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for data, labels in loader:\n",
    "            labels = labels.cuda()\n",
    "            predictions_per_class = model(data.cuda())\n",
    "            highest_prediction, highest_prediction_class = predictions_per_class.max(1)\n",
    "\n",
    "            # how good are we? compare output with the target classes\n",
    "            loss = F.nll_loss(predictions_per_class, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += torch.sum(highest_prediction_class == labels)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        accuracy = total_correct.item()/len(loader)\n",
    "        train_loss = total_loss/len(loader)\n",
    "        validation_loss, validation_accuracy = evalulate(model, validation_loader)\n",
    "        stats = f'Epoch: {epoch}, TL: {train_loss}, VL: {validation_loss.item()}, TA: {accuracy}, VA: {validation_accuracy}'\n",
    "        print(stats)\n",
    "        f.write(f'{stats}\\n')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_size, loader, validation_loader = load_dataset()\n",
    "# model = ModelConv1(kernel_size=5, conv_out_channels=20, linear_size=500).cuda()\n",
    "model = ModelConv2(input_size=100, kernel_size=5, conv_out_channels=20, linear_size=500).cuda()\n",
    "learn(model, loader, validation_loader, epochs=10000, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
