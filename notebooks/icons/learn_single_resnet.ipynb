{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from training_loop import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "LABELS = sorted([i[:-4] for i in os.listdir('icons')])\n",
    "NUM_CLASSES = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    \"\"\"\n",
    "    Add gaussian noise to a numpy.ndarray (H x W x C)\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, sigma, random_state=np.random):\n",
    "        self.sigma = sigma\n",
    "        self.mean = mean\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __call__(self, image):\n",
    "        row, col, ch = image.shape\n",
    "        gauss = self.random_state.normal(self.mean, self.sigma, (row, col, ch))\n",
    "        gauss = gauss.reshape(row, col, ch)\n",
    "        image += torch.from_numpy(gauss).float()\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IconsDataset(Dataset):\n",
    "    def __init__(self, directory, labels, transform=None):\n",
    "        self.directory = directory\n",
    "        self.files = os.listdir(directory)[:1000]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        f = self.files[index]\n",
    "        # image\n",
    "        image = Image.open(os.path.join(self.directory, f))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # labels\n",
    "        label = f.split('.')[0].split('_')[1]\n",
    "        label = LABELS.index(label)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "    def input_size(self):\n",
    "        return 100 * 100 * 3\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        #GaussianNoise(0.01, 0.001),\n",
    "    ])\n",
    "    \n",
    "    d = IconsDataset('images_single_224/', LABELS, transform=transform)\n",
    "    size = len(d)\n",
    "    train, validate = random_split(d, [int(size * 0.8), int(size * 0.2)])\n",
    "    \n",
    "    loader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "    validation_loader = DataLoader(validate, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return d.input_size(), loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, TL: 2.82135, VL: 3.02172, TA: 0.10500, VA: 0.05500\n",
      "Epoch: 1, TL: 2.09282, VL: 2.08305, TA: 0.25375, VA: 0.20000\n",
      "Epoch: 2, TL: 1.77519, VL: 1.87521, TA: 0.38375, VA: 0.25500\n",
      "Epoch: 3, TL: 1.43635, VL: 1.81388, TA: 0.55625, VA: 0.32000\n",
      "Epoch: 4, TL: 1.06223, VL: 2.18336, TA: 0.72250, VA: 0.26000\n",
      "Epoch: 5, TL: 0.81416, VL: 3.99741, TA: 0.80625, VA: 0.21500\n",
      "Epoch: 6, TL: 0.66446, VL: 4.67822, TA: 0.85625, VA: 0.13000\n",
      "Epoch: 7, TL: 0.39619, VL: 3.48232, TA: 0.91000, VA: 0.13500\n",
      "Epoch: 8, TL: 0.28634, VL: 4.65652, TA: 0.92750, VA: 0.13000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(512, NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "input_size, loader, validation_loader = load_dataset()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=0.0001)\n",
    "train_model('resnet18_single_4_batchsize20', model, {'train': loader, 'val': validation_loader}, criterion, optimizer, device, num_epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
