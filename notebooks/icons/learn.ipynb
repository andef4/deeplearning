{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "LABELS = sorted([i[:-4] for i in os.listdir('icons')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IconsDataset(Dataset):\n",
    "    def __init__(self, directory, labels, transform=None):\n",
    "        self.directory = directory\n",
    "        self.files = os.listdir(directory)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        f = self.files[index]\n",
    "        # image\n",
    "        image = Image.open(os.path.join(self.directory, f))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # labels\n",
    "        label_strings = f[:-4].split('_')\n",
    "        labels = []\n",
    "        for l in LABELS:\n",
    "            if l in label_strings:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        \n",
    "        return image, torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def input_size(self):\n",
    "        return 100 * 100 * 3\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    d = IconsDataset('images/', LABELS, transform=transforms.ToTensor())\n",
    "    train, validate = random_split(d, [800, 200])\n",
    "    \n",
    "    loader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "    validation_loader = DataLoader(validate, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return d.input_size(), loader, validation_loader\n",
    "\n",
    "s, l, v = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
