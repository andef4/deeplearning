{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "LABELS = sorted([i[:-4] for i in os.listdir('icons')])\n",
    "NUM_CLASSES = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IconsDataset(Dataset):\n",
    "    def __init__(self, directory, labels, transform=None):\n",
    "        self.directory = directory\n",
    "        self.files = os.listdir(directory)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        f = self.files[index]\n",
    "        # image\n",
    "        image = Image.open(os.path.join(self.directory, f))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # labels\n",
    "        label_strings = f[:-4].split('_')\n",
    "        labels = []\n",
    "        for l in LABELS:\n",
    "            if l in label_strings:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        \n",
    "        return image, torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    def input_size(self):\n",
    "        return 100 * 100 * 3\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    d = IconsDataset('images/', LABELS, transform=transforms.ToTensor())\n",
    "    train, validate = random_split(d, [800, 200])\n",
    "    \n",
    "    loader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "    validation_loader = DataLoader(validate, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return d.input_size(), loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv1(nn.Module):\n",
    "    def __init__(self, kernel_size=5, conv_out_channels=5, linear_size=50):\n",
    "        super().__init__()\n",
    "        if kernel_size % 2 != 1:\n",
    "            raise Exception('Only odd kernel_size are supported')\n",
    "        self.conv_out_channels = conv_out_channels\n",
    "        self.conv1 = nn.Conv2d(3, conv_out_channels, kernel_size=kernel_size)\n",
    "        # convolution kernels are not applied on the border of the image, because the kernel would be outside the image\n",
    "        conv_layer_output_size = int(100 - (kernel_size - 1))\n",
    "        self.pooled_pixels = int(conv_layer_output_size / 2)\n",
    "        self.h1 = nn.Linear(self.pooled_pixels * self.pooled_pixels  * conv_out_channels, linear_size)\n",
    "        self.h2 = nn.Linear(linear_size, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.pooled_pixels * self.pooled_pixels * self.conv_out_channels)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def evalulate(model, validation_loader):\n",
    "    model.eval()\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for data, labels in validation_loader:\n",
    "        predictions = model(data.cuda())\n",
    "        loss = criterion(predictions, labels.cuda())    \n",
    "        total_loss += loss.data.mean()\n",
    "    return total_loss/len(validation_loader)\n",
    "\n",
    "def learn(model, loader, validation_loader, epochs=30, learning_rate=0.001):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "    f = open(f'{datetime.now().isoformat()}.txt', 'w', buffering=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for data, labels in loader:\n",
    "            predictions = model(data.cuda())\n",
    "            loss = criterion(predictions, labels.cuda())\n",
    "            \n",
    "            total_loss += loss.data.mean()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = total_loss/len(loader)\n",
    "        validation_loss = evalulate(model, validation_loader)\n",
    "        stats = f'Epoch: {epoch}, Train Loss: {train_loss}, Validation Loss: {validation_loss.item()}'\n",
    "        print(stats)\n",
    "        f.write(f'{stats}\\n')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, loader, validation_loader = load_dataset()\n",
    "model = ModelConv1(kernel_size=5, conv_out_channels=5, linear_size=50).cuda()\n",
    "learn(model, loader, validation_loader, epochs=10000, learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
