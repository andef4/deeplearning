{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import mnist\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 20\n",
    "LEARING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "dataset = mnist.MNIST('./data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# validation set\n",
    "validation_dataset = mnist.MNIST('./data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "validation_loader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "# input_size\n",
    "data, _ = next(iter(loader))\n",
    "x_size = len(data[0][0][0])\n",
    "y_size = len(data[0][0])\n",
    "input_size = x_size * y_size  # flatten 28x28 tensor to 1x784 tensor\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 50\n",
    "\n",
    "class Model2Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        self.h3 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 500\n",
    "\n",
    "class Model1Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "\n",
    "class Model1LinearDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv1(nn.Module):\n",
    "    def __init__(self, kernel_size=5, conv_out_channels=5, linear_size=50):\n",
    "        super().__init__()\n",
    "        if kernel_size % 2 != 1:\n",
    "            raise Exception('Only odd kernel_size are supported')\n",
    "        self.conv_out_channels = conv_out_channels\n",
    "        self.conv1 = nn.Conv2d(1, conv_out_channels, kernel_size=kernel_size)\n",
    "        # convolution kernels are not applied on the border of the image, because the kernel would be outside the image\n",
    "        conv_layer_output_size = int(x_size - (kernel_size - 1))\n",
    "        self.pooled_pixels = int(conv_layer_output_size / 2)\n",
    "        self.h1 = nn.Linear(self.pooled_pixels * self.pooled_pixels  * conv_out_channels, linear_size)\n",
    "        self.h2 = nn.Linear(linear_size, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.pooled_pixels * self.pooled_pixels * self.conv_out_channels)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv2(nn.Module):\n",
    "    def __init__(self, kernel_size=5, conv_out_channels1=5, conv_out_channels2=5, linear_size=50):\n",
    "        super().__init__()\n",
    "        if kernel_size % 2 != 1:\n",
    "            raise Exception('Only odd kernel_size are supported')\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, conv_out_channels1, kernel_size=kernel_size)\n",
    "        conv_out_channels1 = conv_out_channels1\n",
    "        conv_layer_output_size1 = int(x_size - (kernel_size - 1))\n",
    "        pooled_pixels1 = int(conv_layer_output_size1 / 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(conv_out_channels1, conv_out_channels2, kernel_size=kernel_size)\n",
    "        self.conv_out_channels2 = conv_out_channels2\n",
    "        conv_layer_output_size2 = int(pooled_pixels1 - (kernel_size - 1))\n",
    "        self.pooled_pixels2 = int(conv_layer_output_size2 / 2)\n",
    "\n",
    "        self.h1 = nn.Linear(self.pooled_pixels2 * self.pooled_pixels2  * conv_out_channels2, linear_size)\n",
    "        self.h2 = nn.Linear(linear_size, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = x.view(-1, self.pooled_pixels2 * self.pooled_pixels2 * self.conv_out_channels2)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalulate(model):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    for data, labels in validation_loader:\n",
    "        predictions_per_class = model(data.cuda())\n",
    "        _, highest_prediction_class = predictions_per_class.max(1)\n",
    "        loss += F.nll_loss(predictions_per_class, labels.cuda())\n",
    "    return loss/len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def learn(model, epochs=30):\n",
    "    optimizer = Adam(params=model.parameters(), lr=LEARING_RATE)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for data, labels in loader:\n",
    "            predictions_per_class = model(data.cuda())\n",
    "            highest_prediction, highest_prediction_class = predictions_per_class.max(1)\n",
    "\n",
    "            # how good are we? compare output with the target classes\n",
    "            loss = F.nll_loss(predictions_per_class, labels.cuda())\n",
    "\n",
    "            model.zero_grad() # ???\n",
    "            loss.backward() # backpropagate\n",
    "            optimizer.step()\n",
    "        \n",
    "        validation_loss = evalulate(model)\n",
    "        print(f'Epoch: {epoch}, Loss: {validation_loss.item()}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model1Linear().cuda()\n",
    "learn(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_size': 5, 'conv_out_channels': 5, 'linear_size': 500}\n",
      "Epoch: 0, Loss: -0.9600119590759277\n",
      "Epoch: 1, Loss: -0.9807263612747192\n",
      "Epoch: 2, Loss: -0.9830785989761353\n",
      "Epoch: 3, Loss: -0.985017716884613\n",
      "Epoch: 4, Loss: -0.9821376800537109\n",
      "Epoch: 5, Loss: -0.9865939617156982\n",
      "Epoch: 6, Loss: -0.9883762001991272\n",
      "Epoch: 7, Loss: -0.9888348579406738\n",
      "Epoch: 8, Loss: -0.9915488362312317\n",
      "Epoch: 9, Loss: -0.9904070496559143\n",
      "Epoch: 10, Loss: -0.9911392331123352\n",
      "Epoch: 11, Loss: -0.9909926652908325\n",
      "Epoch: 12, Loss: -0.9933447241783142\n",
      "Epoch: 13, Loss: -0.987438440322876\n",
      "Epoch: 14, Loss: -0.992839515209198\n",
      "Epoch: 15, Loss: -0.9918549060821533\n",
      "Epoch: 16, Loss: -0.9927961230278015\n",
      "Epoch: 17, Loss: -0.9918797612190247\n",
      "Epoch: 18, Loss: -0.9921971559524536\n",
      "Epoch: 19, Loss: -0.9942952394485474\n",
      "Epoch: 20, Loss: -0.9922376275062561\n",
      "Epoch: 21, Loss: -0.9938608407974243\n",
      "Epoch: 22, Loss: -0.9941400289535522\n",
      "Epoch: 23, Loss: -0.993842601776123\n",
      "Epoch: 24, Loss: -0.9933632612228394\n",
      "Epoch: 25, Loss: -0.9947407841682434\n",
      "Epoch: 26, Loss: -0.9947521090507507\n",
      "Epoch: 27, Loss: -0.9943171143531799\n",
      "Epoch: 28, Loss: -0.9952201843261719\n",
      "Epoch: 29, Loss: -0.9931232929229736\n",
      "Epoch: 30, Loss: -0.9940003752708435\n",
      "Epoch: 31, Loss: -0.9954977631568909\n",
      "Epoch: 32, Loss: -0.9955054521560669\n",
      "Epoch: 33, Loss: -0.9957978129386902\n",
      "Epoch: 34, Loss: -0.9947999715805054\n"
     ]
    }
   ],
   "source": [
    "# 1 convolution layer\n",
    "configs = [\n",
    "    #{'kernel_size': 5, 'conv_out_channels': 1, 'linear_size': 50},\n",
    "    {'kernel_size': 5, 'conv_out_channels': 5, 'linear_size': 500},\n",
    "    #{'kernel_size': 3, 'conv_out_channels': 2, 'linear_size': 500},\n",
    "    #{'kernel_size': 3, 'conv_out_channels': 2, 'linear_size': 300},\n",
    "    #{'kernel_size': 3, 'conv_out_channels': 2, 'linear_size': 200},\n",
    "    #{'kernel_size': 5, 'conv_out_channels': 2, 'linear_size': 50},\n",
    "    #{'kernel_size': 5, 'conv_out_channels': 5, 'linear_size': 50},\n",
    "    #{'kernel_size': 9, 'conv_out_channels': 5, 'linear_size': 500},\n",
    "    #{'kernel_size': 7, 'conv_out_channels': 5, 'linear_size': 500},\n",
    "    #{'kernel_size': 11, 'conv_out_channels': 5, 'linear_size': 500},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    torch.cuda.empty_cache()\n",
    "    model = ModelConv1(**config).cuda()\n",
    "    try:\n",
    "        learn(model, 100)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2 convolution layers\n",
    "configs = [\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 5, 'conv_out_channels2': 5, 'linear_size': 50},\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 5, 'conv_out_channels2': 5, 'linear_size': 300},\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 5, 'conv_out_channels2': 5, 'linear_size': 500},\n",
    "    \n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 5, 'conv_out_channels2': 10, 'linear_size': 50},\n",
    "    {'kernel_size': 5, 'conv_out_channels1': 5, 'conv_out_channels2': 10, 'linear_size': 300},\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 5, 'conv_out_channels2': 10, 'linear_size': 500},\n",
    "    \n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 10, 'conv_out_channels2': 10, 'linear_size': 50},\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 10, 'conv_out_channels2': 10, 'linear_size': 300},\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 10, 'conv_out_channels2': 10, 'linear_size': 500},\n",
    "    \n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 10, 'conv_out_channels2': 20, 'linear_size': 50},\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 10, 'conv_out_channels2': 20, 'linear_size': 300},\n",
    "    #{'kernel_size': 5, 'conv_out_channels1': 10, 'conv_out_channels2': 20, 'linear_size': 500},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    torch.cuda.empty_cache()\n",
    "    model = ModelConv2(**config).cuda()\n",
    "    try:\n",
    "        learn(model, 100)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
