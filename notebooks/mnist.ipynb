{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import mnist\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 200\n",
    "LEARING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "dataset = mnist.MNIST('./data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# validation set\n",
    "validation_dataset = mnist.MNIST('./data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "validation_loader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "# input_size\n",
    "data, _ = next(iter(loader))\n",
    "x_size = len(data[0][0][0])\n",
    "y_size = len(data[0][0])\n",
    "input_size = x_size * y_size  # flatten 28x28 tensor to 1x784 tensor\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 50\n",
    "\n",
    "class Model2Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        self.h3 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "\n",
    "class Model1Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "\n",
    "class Model1LinearDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "\n",
    "class ModelConv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "        \n",
    "        # (in_channels, out_channels, kernel_size\n",
    "        \n",
    "        # in_channels=1 (input image is grayscale => one channel)\n",
    "        # out_channels=10 ()\n",
    "        \n",
    "        # (old_width + 2*padding - kernel_size)/stride + 1\n",
    "        # (28 + 2*0 - 5)/1 + 1\n",
    "        \n",
    "        # stride=1, padding=0, dilation=1, groups=1\n",
    "        # 28 + 2*0 - 1 * (5 -1) -1 + 1 = 24\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "\n",
    "class ModelConv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, HIDDEN_SIZE)\n",
    "        self.h2 = nn.Linear(HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.data.view(-1, input_size)\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d dropout\n",
    "# 2d pool\n",
    "# layer count/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalulate(model):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    for data, labels in validation_loader:\n",
    "        predictions_per_class = model(data.cuda())\n",
    "        _, highest_prediction_class = predictions_per_class.max(1)\n",
    "        loss += F.nll_loss(predictions_per_class, labels.cuda())\n",
    "    return loss/len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: -0.8663519620895386\n",
      "Epoch: 1, Loss: -0.903980016708374\n",
      "Epoch: 2, Loss: -0.9190024137496948\n",
      "Epoch: 3, Loss: -0.9279651045799255\n",
      "Epoch: 4, Loss: -0.9344733953475952\n",
      "Epoch: 5, Loss: -0.9396764636039734\n",
      "Epoch: 6, Loss: -0.9440144896507263\n",
      "Epoch: 7, Loss: -0.9476982951164246\n",
      "Epoch: 8, Loss: -0.9500924944877625\n",
      "Epoch: 9, Loss: -0.9528350234031677\n",
      "Epoch: 10, Loss: -0.953758180141449\n",
      "Epoch: 11, Loss: -0.9566394090652466\n",
      "Epoch: 12, Loss: -0.9583799242973328\n",
      "Epoch: 13, Loss: -0.9598350524902344\n",
      "Epoch: 14, Loss: -0.9610174894332886\n",
      "Epoch: 15, Loss: -0.9623236060142517\n",
      "Epoch: 16, Loss: -0.9629250168800354\n",
      "Epoch: 17, Loss: -0.9639860987663269\n",
      "Epoch: 18, Loss: -0.96522057056427\n",
      "Epoch: 19, Loss: -0.9657012224197388\n",
      "Epoch: 20, Loss: -0.9664510488510132\n",
      "Epoch: 21, Loss: -0.966827929019928\n",
      "Epoch: 22, Loss: -0.9676613807678223\n",
      "Epoch: 23, Loss: -0.9682779312133789\n",
      "Epoch: 24, Loss: -0.9685783982276917\n",
      "Epoch: 25, Loss: -0.9699547290802002\n",
      "Epoch: 26, Loss: -0.9698930382728577\n",
      "Epoch: 27, Loss: -0.9708006978034973\n",
      "Epoch: 28, Loss: -0.9712110757827759\n",
      "Epoch: 29, Loss: -0.9717444181442261\n",
      "Epoch: 30, Loss: -0.9719375967979431\n",
      "Epoch: 31, Loss: -0.9727160930633545\n",
      "Epoch: 32, Loss: -0.9732034802436829\n",
      "Epoch: 33, Loss: -0.973270058631897\n",
      "Epoch: 34, Loss: -0.9737115502357483\n",
      "Epoch: 35, Loss: -0.9739749431610107\n",
      "Epoch: 36, Loss: -0.974158763885498\n",
      "Epoch: 37, Loss: -0.9743883609771729\n",
      "Epoch: 38, Loss: -0.9741630554199219\n",
      "Epoch: 39, Loss: -0.9753589034080505\n",
      "Epoch: 40, Loss: -0.9753480553627014\n",
      "Epoch: 41, Loss: -0.9759027361869812\n",
      "Epoch: 42, Loss: -0.9758387207984924\n",
      "Epoch: 43, Loss: -0.9759240746498108\n",
      "Epoch: 44, Loss: -0.9764901995658875\n",
      "Epoch: 45, Loss: -0.9767932295799255\n",
      "Epoch: 46, Loss: -0.9771126508712769\n",
      "Epoch: 47, Loss: -0.977534294128418\n",
      "Epoch: 48, Loss: -0.9774201512336731\n",
      "Epoch: 49, Loss: -0.9774552583694458\n",
      "Epoch: 50, Loss: -0.9778594970703125\n",
      "Epoch: 51, Loss: -0.9774916768074036\n",
      "Epoch: 52, Loss: -0.978298544883728\n",
      "Epoch: 53, Loss: -0.978373110294342\n",
      "Epoch: 54, Loss: -0.9784469604492188\n",
      "Epoch: 55, Loss: -0.9783766865730286\n",
      "Epoch: 56, Loss: -0.9785634875297546\n",
      "Epoch: 57, Loss: -0.9788944721221924\n",
      "Epoch: 58, Loss: -0.979127824306488\n",
      "Epoch: 59, Loss: -0.9794830679893494\n",
      "Epoch: 60, Loss: -0.9795207977294922\n",
      "Epoch: 61, Loss: -0.979745626449585\n",
      "Epoch: 62, Loss: -0.9794708490371704\n",
      "Epoch: 63, Loss: -0.9798702001571655\n",
      "Epoch: 64, Loss: -0.9799326062202454\n",
      "Epoch: 65, Loss: -0.979902982711792\n",
      "Epoch: 66, Loss: -0.9805301427841187\n",
      "Epoch: 67, Loss: -0.9803125262260437\n",
      "Epoch: 68, Loss: -0.980474054813385\n",
      "Epoch: 69, Loss: -0.9807435274124146\n",
      "Epoch: 70, Loss: -0.980796217918396\n",
      "Epoch: 71, Loss: -0.9810000658035278\n",
      "Epoch: 72, Loss: -0.9810593724250793\n",
      "Epoch: 73, Loss: -0.9810894727706909\n",
      "Epoch: 74, Loss: -0.9809438586235046\n",
      "Epoch: 75, Loss: -0.9812787175178528\n",
      "Epoch: 76, Loss: -0.9810062646865845\n",
      "Epoch: 77, Loss: -0.9814561009407043\n",
      "Epoch: 78, Loss: -0.9818266034126282\n",
      "Epoch: 79, Loss: -0.9816886782646179\n",
      "Epoch: 80, Loss: -0.9818129539489746\n",
      "Epoch: 81, Loss: -0.9816632270812988\n",
      "Epoch: 82, Loss: -0.9820430874824524\n",
      "Epoch: 83, Loss: -0.981938898563385\n",
      "Epoch: 84, Loss: -0.9820799827575684\n",
      "Epoch: 85, Loss: -0.981886625289917\n",
      "Epoch: 86, Loss: -0.9820940494537354\n",
      "Epoch: 87, Loss: -0.9823378920555115\n",
      "Epoch: 88, Loss: -0.9821645617485046\n",
      "Epoch: 89, Loss: -0.9824523329734802\n",
      "Epoch: 90, Loss: -0.9825354218482971\n",
      "Epoch: 91, Loss: -0.9824917912483215\n",
      "Epoch: 92, Loss: -0.9826257824897766\n",
      "Epoch: 93, Loss: -0.9824889302253723\n",
      "Epoch: 94, Loss: -0.9827874898910522\n",
      "Epoch: 95, Loss: -0.9829832911491394\n",
      "Epoch: 96, Loss: -0.9828018546104431\n",
      "Epoch: 97, Loss: -0.9829245209693909\n",
      "Epoch: 98, Loss: -0.9832981824874878\n",
      "Epoch: 99, Loss: -0.9833484888076782\n",
      "Epoch: 100, Loss: -0.9829028844833374\n",
      "Epoch: 101, Loss: -0.9833464026451111\n",
      "Epoch: 102, Loss: -0.9834098815917969\n",
      "Epoch: 103, Loss: -0.9834612011909485\n",
      "Epoch: 104, Loss: -0.9832390546798706\n",
      "Epoch: 105, Loss: -0.9836106896400452\n",
      "Epoch: 106, Loss: -0.9834549427032471\n",
      "Epoch: 107, Loss: -0.9837810397148132\n",
      "Epoch: 108, Loss: -0.9838489890098572\n",
      "Epoch: 109, Loss: -0.9835920333862305\n",
      "Epoch: 110, Loss: -0.9838463664054871\n",
      "Epoch: 111, Loss: -0.9836087226867676\n",
      "Epoch: 112, Loss: -0.9839334487915039\n",
      "Epoch: 113, Loss: -0.983715832233429\n",
      "Epoch: 114, Loss: -0.9841477870941162\n",
      "Epoch: 115, Loss: -0.9840427041053772\n",
      "Epoch: 116, Loss: -0.9843378663063049\n",
      "Epoch: 117, Loss: -0.9840688109397888\n",
      "Epoch: 118, Loss: -0.9843126535415649\n",
      "Epoch: 119, Loss: -0.9843230247497559\n",
      "Epoch: 120, Loss: -0.9841027855873108\n",
      "Epoch: 121, Loss: -0.9846107959747314\n",
      "Epoch: 122, Loss: -0.9845691323280334\n",
      "Epoch: 123, Loss: -0.9845504760742188\n",
      "Epoch: 124, Loss: -0.9841630458831787\n",
      "Epoch: 125, Loss: -0.984453558921814\n",
      "Epoch: 126, Loss: -0.9849560856819153\n",
      "Epoch: 127, Loss: -0.9848287105560303\n",
      "Epoch: 128, Loss: -0.984720766544342\n",
      "Epoch: 129, Loss: -0.9847989082336426\n",
      "Epoch: 130, Loss: -0.9851220846176147\n",
      "Epoch: 131, Loss: -0.985469400882721\n",
      "Epoch: 132, Loss: -0.9851541519165039\n",
      "Epoch: 133, Loss: -0.9853581190109253\n",
      "Epoch: 134, Loss: -0.9851949214935303\n",
      "Epoch: 135, Loss: -0.9854466915130615\n",
      "Epoch: 136, Loss: -0.9851588010787964\n",
      "Epoch: 137, Loss: -0.9853640794754028\n",
      "Epoch: 138, Loss: -0.9855017066001892\n",
      "Epoch: 139, Loss: -0.9854806661605835\n",
      "Epoch: 140, Loss: -0.9854868054389954\n",
      "Epoch: 141, Loss: -0.9856140613555908\n",
      "Epoch: 142, Loss: -0.9855598211288452\n",
      "Epoch: 143, Loss: -0.9857973456382751\n",
      "Epoch: 144, Loss: -0.9857056140899658\n",
      "Epoch: 145, Loss: -0.9859034419059753\n",
      "Epoch: 146, Loss: -0.9857944846153259\n",
      "Epoch: 147, Loss: -0.9857642650604248\n",
      "Epoch: 148, Loss: -0.9856542944908142\n",
      "Epoch: 149, Loss: -0.9860708117485046\n",
      "Epoch: 150, Loss: -0.9860026240348816\n",
      "Epoch: 151, Loss: -0.9860363006591797\n",
      "Epoch: 152, Loss: -0.9859932661056519\n",
      "Epoch: 153, Loss: -0.9857915639877319\n",
      "Epoch: 154, Loss: -0.9863433241844177\n",
      "Epoch: 155, Loss: -0.9865372180938721\n",
      "Epoch: 156, Loss: -0.9862109422683716\n",
      "Epoch: 157, Loss: -0.986328125\n",
      "Epoch: 158, Loss: -0.986359179019928\n",
      "Epoch: 159, Loss: -0.9862620234489441\n",
      "Epoch: 160, Loss: -0.9861013293266296\n",
      "Epoch: 161, Loss: -0.9863954782485962\n",
      "Epoch: 162, Loss: -0.9863101243972778\n",
      "Epoch: 163, Loss: -0.9864152073860168\n",
      "Epoch: 164, Loss: -0.9863260388374329\n",
      "Epoch: 165, Loss: -0.986245334148407\n",
      "Epoch: 166, Loss: -0.9862733483314514\n",
      "Epoch: 167, Loss: -0.9861013293266296\n",
      "Epoch: 168, Loss: -0.9865443110466003\n",
      "Epoch: 169, Loss: -0.9863943457603455\n",
      "Epoch: 170, Loss: -0.9865975379943848\n",
      "Epoch: 171, Loss: -0.9865847826004028\n",
      "Epoch: 172, Loss: -0.9865298867225647\n",
      "Epoch: 173, Loss: -0.9869043231010437\n",
      "Epoch: 174, Loss: -0.987002968788147\n",
      "Epoch: 175, Loss: -0.9868643283843994\n",
      "Epoch: 176, Loss: -0.9869662523269653\n",
      "Epoch: 177, Loss: -0.9869593381881714\n",
      "Epoch: 178, Loss: -0.9869064688682556\n",
      "Epoch: 179, Loss: -0.987065851688385\n",
      "Epoch: 180, Loss: -0.9868963956832886\n",
      "Epoch: 181, Loss: -0.9869213104248047\n",
      "Epoch: 182, Loss: -0.9869971871376038\n",
      "Epoch: 183, Loss: -0.987113356590271\n",
      "Epoch: 184, Loss: -0.9872854948043823\n",
      "Epoch: 185, Loss: -0.9870787858963013\n",
      "Epoch: 186, Loss: -0.9872021675109863\n",
      "Epoch: 187, Loss: -0.9871606826782227\n",
      "Epoch: 188, Loss: -0.9873180389404297\n",
      "Epoch: 189, Loss: -0.9868878126144409\n",
      "Epoch: 190, Loss: -0.9871716499328613\n",
      "Epoch: 191, Loss: -0.987152636051178\n",
      "Epoch: 192, Loss: -0.9871072769165039\n",
      "Epoch: 193, Loss: -0.9870058298110962\n",
      "Epoch: 194, Loss: -0.9872990250587463\n",
      "Epoch: 195, Loss: -0.9871503114700317\n",
      "Epoch: 196, Loss: -0.9875144958496094\n",
      "Epoch: 197, Loss: -0.9872044920921326\n",
      "Epoch: 198, Loss: -0.9873910546302795\n",
      "Epoch: 199, Loss: -0.9876074194908142\n",
      "Epoch: 200, Loss: -0.9873378872871399\n",
      "Epoch: 201, Loss: -0.9875869750976562\n",
      "Epoch: 202, Loss: -0.9870298504829407\n",
      "Epoch: 203, Loss: -0.9877883195877075\n",
      "Epoch: 204, Loss: -0.9877628684043884\n",
      "Epoch: 205, Loss: -0.9872862696647644\n",
      "Epoch: 206, Loss: -0.9872603416442871\n",
      "Epoch: 207, Loss: -0.9874065518379211\n",
      "Epoch: 208, Loss: -0.9877564907073975\n",
      "Epoch: 209, Loss: -0.9877052307128906\n",
      "Epoch: 210, Loss: -0.9878947138786316\n",
      "Epoch: 211, Loss: -0.9875909686088562\n",
      "Epoch: 212, Loss: -0.987749457359314\n",
      "Epoch: 213, Loss: -0.9879372119903564\n",
      "Epoch: 214, Loss: -0.9878643155097961\n",
      "Epoch: 215, Loss: -0.9880185127258301\n",
      "Epoch: 216, Loss: -0.9879257678985596\n",
      "Epoch: 217, Loss: -0.9879485368728638\n",
      "Epoch: 218, Loss: -0.9880549311637878\n",
      "Epoch: 219, Loss: -0.9880343675613403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, Loss: -0.9881453514099121\n",
      "Epoch: 221, Loss: -0.9878230094909668\n",
      "Epoch: 222, Loss: -0.9882858395576477\n",
      "Epoch: 223, Loss: -0.9880897998809814\n",
      "Epoch: 224, Loss: -0.9883807897567749\n",
      "Epoch: 225, Loss: -0.9881869554519653\n",
      "Epoch: 226, Loss: -0.9882554411888123\n",
      "Epoch: 227, Loss: -0.9884114861488342\n",
      "Epoch: 228, Loss: -0.9883939623832703\n",
      "Epoch: 229, Loss: -0.9881075024604797\n",
      "Epoch: 230, Loss: -0.9881932735443115\n",
      "Epoch: 231, Loss: -0.9882181882858276\n",
      "Epoch: 232, Loss: -0.9879837036132812\n",
      "Epoch: 233, Loss: -0.9881662130355835\n",
      "Epoch: 234, Loss: -0.9882230758666992\n",
      "Epoch: 235, Loss: -0.9885725975036621\n",
      "Epoch: 236, Loss: -0.9882437586784363\n",
      "Epoch: 237, Loss: -0.9884817600250244\n",
      "Epoch: 238, Loss: -0.9885255098342896\n",
      "Epoch: 239, Loss: -0.9882961511611938\n",
      "Epoch: 240, Loss: -0.9885178804397583\n",
      "Epoch: 241, Loss: -0.9885518550872803\n",
      "Epoch: 242, Loss: -0.9884817004203796\n",
      "Epoch: 243, Loss: -0.9885640740394592\n",
      "Epoch: 244, Loss: -0.9885975122451782\n",
      "Epoch: 245, Loss: -0.9883281588554382\n",
      "Epoch: 246, Loss: -0.9887040257453918\n",
      "Epoch: 247, Loss: -0.988595187664032\n",
      "Epoch: 248, Loss: -0.9883641600608826\n",
      "Epoch: 249, Loss: -0.9886143207550049\n",
      "Epoch: 250, Loss: -0.988513708114624\n",
      "Epoch: 251, Loss: -0.9886036515235901\n",
      "Epoch: 252, Loss: -0.988962709903717\n",
      "Epoch: 253, Loss: -0.9888721704483032\n",
      "Epoch: 254, Loss: -0.9885961413383484\n",
      "Epoch: 255, Loss: -0.9885903000831604\n",
      "Epoch: 256, Loss: -0.9888303875923157\n",
      "Epoch: 257, Loss: -0.9888796210289001\n",
      "Epoch: 258, Loss: -0.9888620972633362\n",
      "Epoch: 259, Loss: -0.9890559911727905\n",
      "Epoch: 260, Loss: -0.9888364672660828\n",
      "Epoch: 261, Loss: -0.988717794418335\n",
      "Epoch: 262, Loss: -0.9889115691184998\n",
      "Epoch: 263, Loss: -0.9888832569122314\n",
      "Epoch: 264, Loss: -0.9887815713882446\n",
      "Epoch: 265, Loss: -0.9886013865470886\n",
      "Epoch: 266, Loss: -0.9888235926628113\n",
      "Epoch: 267, Loss: -0.9889779090881348\n",
      "Epoch: 268, Loss: -0.988959550857544\n",
      "Epoch: 269, Loss: -0.9889418482780457\n",
      "Epoch: 270, Loss: -0.9887598156929016\n",
      "Epoch: 271, Loss: -0.9886844158172607\n",
      "Epoch: 272, Loss: -0.9889655709266663\n",
      "Epoch: 273, Loss: -0.9888809323310852\n",
      "Epoch: 274, Loss: -0.9888132214546204\n",
      "Epoch: 275, Loss: -0.9890226721763611\n",
      "Epoch: 276, Loss: -0.988784909248352\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4fab0687a229>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}, Loss: {validation_loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-9f7fc021e91e>\u001b[0m in \u001b[0;36mevalulate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mpredictions_per_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighest_prediction_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_per_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekte/deeplearning/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekte/deeplearning/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekte/deeplearning/venv/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekte/deeplearning/venv/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekte/deeplearning/venv/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def learn():\n",
    "    model = Model1LinearDropout().cuda()\n",
    "    optimizer = Adam(params=model.parameters(), lr=LEARING_RATE)\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        for data, labels in loader:\n",
    "            predictions_per_class = model(data.cuda())\n",
    "            highest_prediction, highest_prediction_class = predictions_per_class.max(1)\n",
    "\n",
    "            # how good are we? compare output with the target classes\n",
    "            loss = F.nll_loss(predictions_per_class, labels.cuda())\n",
    "\n",
    "            model.zero_grad() # ???\n",
    "            loss.backward() # backpropagate\n",
    "            optimizer.step()\n",
    "        \n",
    "        validation_loss = evalulate(model)\n",
    "        print(f'Epoch: {epoch}, Loss: {validation_loss.item()}')\n",
    "        \n",
    "    return model\n",
    "%time model = learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9610, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
